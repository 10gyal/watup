[
  {
    "post_id": "1hir24l",
    "post_content": "OpenAI o3 is equivalent to the #175 best human competitive coder on the planet.",
    "post_url": "https://i.redd.it/kwdo648cx18e1.png",
    "score": 592,
    "author": "MetaKnowing",
    "created_utc": 1734721417.0,
    "num_comments": 187,
    "subreddit": "OpenAI",
    "comments": "\n  └─ CS job market for junior hiring is about to get even tougher...\n     Score: 244 | Author: TheInfiniteUniverse_\n\n      └─ FYI, the more powerful 03 model costs like $7500 in compute per task. The arc agi benchmark cost them around $1.6 million to run.\n         Score: 54 | Author: gthing\n\n          └─ the training of early LLM was super expensive, too. so?\n             Score: 15 | Author: ecnecn\n\n          └─ Sure but:  \n\"There's a basic principle about consumer electronics: it gets more powerful all the time and it gets cheaper all the time.\"  \nWhat happens in a few years when it costs less than an engineer salary to run?\n             Score: 14 | Author: InvestO0O0O0O0r\n\n              └─ That's too optimistic (or pessimistic depending on the POV).\nSmall models don't perform as much and big models need big compute to run.\n                 Score: -4 | Author: Square_Poet_110\n\n                  └─ My point was about the underlying compute infrastructure getting eventually cheaper than an engineer to run, because the hardware gets cheaper and provides more performance per watt, rather than nerfing the model, but sure.\n                     Score: 6 | Author: InvestO0O0O0O0r\n\n                      └─ Hardware doesn't get that much cheaper nowadays.\n                         Score: 0 | Author: Square_Poet_110\n\n      └─ Yet again I have to remind people that it's not solving one-off coding problems that makes someone an engineer. I can't even describe to you the sprawling spaghetti of integrated microservices each with huge repositories of code that would make an extremely costly context window to routinely stay up to date on. And you have to do that while fulfilling customer demands strategically. \n\nAutonomous agents have been interesting but still quite lacking.\n         Score: 34 | Author: forever_downstream\n\n          └─ Are you saying 2026?\n             Score: 19 | Author: VoloNoscere\n\n              └─ Maybe but probably not. Don't get me wrong, it could get there obviously and that's what everyone will say. But what IS there right now is far from taking real software engineer jobs. It's much more distant than people understand.\n                 Score: -1 | Author: forever_downstream\n\n                  └─ Faire point.\n                     Score: 2 | Author: VoloNoscere\n\n                  └─ Except it will take jobs because you'll need less software engineers to do the same amount of work. It's already happening. And it's only going to get better.\n                     Score: 5 | Author: Pitiful_End_5019\n\n                      └─ I work at a big software engineering company and there are zero software engineer jobs currently taken by AI. If they could they would. But they can't. Not yet. \n\nYou have to understand that it's just not there yet.\n                         Score: 6 | Author: forever_downstream\n\n                      └─ Lump of labor fallacy. It may increase the demand for software engineers because they will be so much more productive that even today's marginally profitable use cases would become profitable. New possibilities will open up.\n                         Score: 0 | Author: Navadvisor\n\n          └─ They don't have to solve all problems all the time. They just have to time/cost-effectively solve some problems sometimes to eliminate many jobs (especially junior or even mid-level jobs) - I see senior devs taking lower-tier jobs just to stay employed.\n             Score: 7 | Author: TheGillos\n\n              └─ Most junior engineer jobs aren't expected for them to do much actual work, it's for them to be trained to become a senior engineer. And if anything, AI will make that process more effective. Everyone can use it. \n\nThere aren't a finite number of jobs. If AI helps engineers accomplish their tasks, that just allows the company to produce / create more with the engineers they have, arguably opening up new jobs.\n                 Score: 5 | Author: forever_downstream\n\n                  └─ Hopefully you're right. Stuff like https://layoffs.fyi/ makes me question how much any company actually gives a shit about training anyone up when they can just hire a desperate laid-off worker who is already trained.\n                     Score: 4 | Author: TheGillos\n\n                      └─ Dont let him lie to you. Companies only care about optimizing. If you can get rid of training people in some way, it will be picked.\n                         Score: 2 | Author: ObadiahTheEmperor\n\n                      └─ I'd love to see the number of layoffs compared to number of jobs in tech too, which continues to increase.\n                         Score: 1 | Author: forever_downstream\n\n  └─ Didn’t they say they have an employee rated 3000? Are they top 10 or something?\n     Score: 18 | Author: Spongebubs\n\n      └─ One specific guy\n         Score: 1 | Author: makoto-jung\n\n  └─ Glad I just retired from development.\n     Score: 98 | Author: santaclaws_\n\n      └─ Pls tell what you are doing now\n         Score: 12 | Author: naastiknibba95\n\n          └─ Not much. I'm 67. I invested in real estate, put money in a 401K and stocks. No more working for me.\n             Score: 49 | Author: santaclaws_\n\n              └─ What a good time to cash out stocks!! Congrats\n                 Score: 14 | Author: Conscious-Craft-2647\n\n              └─ You got out at a good time.  Enjoy retirement!\n                 Score: 1 | Author: Ok-Purchase8196\n\n      └─ retired to do what? I need money to feed me.\n         Score: 9 | Author: Double-Cricket-7067\n\n          └─ There are other ways to make money and coding was already a pretty lame one as it was, lol.\n             Score: -28 | Author: akablacktherapper\n\n              └─ Yeah, making 6 figures while sitting on a chair in your pyjamas is a terrible life ...\n                 Score: 3 | Author: Agreeable_Service407\n\n              └─ any suggestions?\n                 Score: 2 | Author: BlueBirdBack\n\n                  └─ AI programming.\n                     Score: 1 | Author: falco_iii\n\n  └─ person who typed 'this is superhuman' doesn't understand what that word means.\n\nI see 174 humans above OpenAI\n     Score: 127 | Author: Constant_List_6407\n\n      └─ He said superhuman result for AI... Kind of seems like an inherently nonsensical sentence\n         Score: 43 | Author: damienVOG\n\n      └─ Question how long those 174 humans will be above ... literally 2 years ago AI was coding like a 7 year old child ... 2 years ago !\n         Score: 23 | Author: Healthy-Nebula-3603\n\n          └─ There is this law of diminishing returns, you know...\n             Score: 2 | Author: Square_Poet_110\n\n          └─ this!\n             Score: 2 | Author: lara0770_\n\n  └─ Where is o1 on this list?\n     Score: 11 | Author: OceanRadioGuy\n\n      └─ Way down. See the live video of day 12. O 1 I remember is about 1600 I guess. Also o3 mini comes at low moderate and high computes with around 2k ELO scores. ELO scores are similar to chess with higher ELO meaning more expert.\n         Score: 13 | Author: AcanthisittaLow8504"
  },
  {
    "post_id": "1hipyjc",
    "post_content": "ARC-AGI has fallen to o3",
    "post_url": "https://i.redd.it/0oaryqpjo18e1.png",
    "score": 486,
    "author": "MetaKnowing",
    "created_utc": 1734718456.0,
    "num_comments": 218,
    "subreddit": "OpenAI",
    "comments": "\n  └─ https://arcprize.org/blog/oai-o3-pub-breakthrough\n\n2k$ compute for o3 (low). 172x more compute than that for o3 (high).\n     Score: 138 | Author: tempaccount287\n\n      └─ $20 per task, does that mean we won't get o3 as Plus subscribers? Only for the $200 subscribers? ;(\n         Score: 47 | Author: daemeh\n\n          └─ Actually that is for the low compute version. For the high compute version it's several thousand dollars per task (according to that report), not even the $200 subscribers will be getting access to that unless optimization decreases costs by many orders of magnitude.\n             Score: 67 | Author: Dyoakom\n\n              └─ This confuses me so much… because I get that this would be marketed at, say, cancer researchers or large financial companies. But who would want to risk letting these things run for as long as they’d need them to, when they’re still based on a model architecture known for hallucinations?\n\nI don’t see this being commercially viable at all until that issue is fixed, or until they can at least make a model that is as close to 100% accurate in a specific field as possible **with** the ability to notice its mistakes or admit it doesn’t know, and flag a human to check it.\n                 Score: 16 | Author: Commercial_Nerve_308\n\n                  └─ This is all a marketing technique so when they release their $1k pm subscription plan for o3, people will think it’s a bargain.\n                     Score: 8 | Author: Essouira12\n\n                      └─ Honestly, $1000 a month is way too low. $200 a month is for those with small businesses or super enthusiasts who are rich.\n\nA Bloomberg Terminal is $2500 a month minimum, and that’s just real-time financial data. If it’s marketed to large firms, I could see a subscription with unlimited o3 access with a “high” level test time being at least **$3K** a month.\n\nI wouldn’t be surprised if OpenAI just give up on the regular consumer now that Google is really competing with them.\n                         Score: 4 | Author: Commercial_Nerve_308\n\n                  └─ Its a proof of concept that basically says: yes, scaling works abd will continue to work. Now lets get to increase compute and make it cheaper\n                     Score: 6 | Author: 32SkyDive\n\n                      └─ It only shows scaling works if you have \"infinite money\" mod enabled.\n                         Score: 1 | Author: Square_Poet_110\n\n          └─ Might be an API thing for foreseeable future.\n             Score: 10 | Author: Ormusn2o\n\n      └─ https://preview.redd.it/42zenhzs528e1.png?width=333&format=png&auto=webp&s=ab186b8d61b7292d4a899d812328b3d2eb801272\n\nwell $6k for the Public run that hit 87.5% so...\n         Score: 18 | Author: coloradical5280\n\n  └─ I have no clue what I'm looking at, please explain?\n     Score: 64 | Author: luckymethod\n\n      └─ Basically It was given problems that could potentially show signs of agi. For example it was given a serious of inputs and outputs. For the last output the ai has to fill it in without any prior instructions. They’re determining the ability of the model reasoning. Basically not it’s memory more it’s ability to understand.\n         Score: 83 | Author: Federal-Lawyer-3128\n\n          └─ Why are these problems considered a sign of AI, they look dead simple to me.\n             Score: 19 | Author: NigroqueSimillima\n\n              └─ That's kind of the point. They're problems that require out of the box thinking that aren't really that hard for people to solve. However, an AI model that only learns by examples would struggle with it. For an AI model to do well on the benchmark, it has to work with problems it hasn't seen before, meaning that it's intelligence must be general. So, while the problems are easy for people to solve, they're specifically designed to force general reasoning out of the models.\n                 Score: 83 | Author: Joboy97\n\n                  └─ Is there a way to know if it was memorizing these questions or it is using novel ideas to create solutions?\n                     Score: -5 | Author: PM_ME_ROMAN_NUDES\n\n                      └─ It is a highly guarded private test set designed specifically against contamination, which is why gpt-4 class models perform so badly.\n                         Score: 36 | Author: RemiFuzzlewuzz\n\n                      └─ its hard to tell since those kind of image tests used here resample iq tests. so pattern matching till you find a match is still a brute force way to solve these.\n\nbut having an AI that does loop processing and has unlimited patterns to use may be a sign of agi and general intelligence. there is only a limited amount of truth and principals in the world. and an AI can learn them all.\n\nbut yeah its also brute forcing intelligence. always reminds me how i learned for math in school since i was lazy. i wrote down codewords for the text variants and assigned a solution path to it. wrote that on a paper and just solved it by pattern matching the tasks. since those tests all had repeating patterns i could solve them without thinking.\n\nbut if you manage to have ai break down things in smaller and smaller patterns it may can solve anything. since thats just what intelligence is. principals and patterns\n                         Score: 8 | Author: Laicbeias\n\n              └─ Exactly- you as a human being- can reason and make inferences and observe patterns with no additional context. That is not trivial for a model hence why this test is a benchmark. To date - no other models have been able to intuitively reason about how to solve these problems. That's why it's exciting- o3 has shown human like reasoning on this test on never before seen problem sets.\n                 Score: 27 | Author: Mindstorms6\n\n                  └─ I just don't see why these are the benchmark for human like reasoning, they look like basic pattern recognization to me. ChatGPT can kick my ass as the LeetCode contest, and that's way more impressive than this.\n                     Score: -11 | Author: NigroqueSimillima\n\n                      └─ Definitely. It's more of a \"at least both are necessary\" type thing. While the exact definition of AGI is somewhat ambiguous- the common belief is that we can't have AGI unless the model can do the most basic of human tasks - one of which is basic pattern recognition on something you've never seen before. Solving this does not imply AGI was achieved- but we'd struggle to say some had achieved AGI without being able to do this task.\n                         Score: 13 | Author: Mindstorms6\n\n                      └─ I understand your confusion but you're looking at it backwards. \n\nThe reason that this is impressive is because previous AI models were incapable of doing this. The idea behind ARC-AGI is finding problems that are easy for humans but very difficult for AI. The reasoning was \"even if AI can do all this incredible stuff, if it still can't do this other stuff that is easy for humans, it can't be called AGI\" \n\nWell, now it can do that other stuff too.\n                         Score: 10 | Author: goshin2568\n\n      └─ Essentially O3 achieved human level performance on the most notable (and difficult) “AGI” benchmark we’ve seen thus far. The breakthrough is in its ability to reason through problems it’s never seen before.\n         Score: 4 | Author: Disgruntled-Cacti\n\n  └─ 20 usd per task? damn! Now we need the cheap AGI goal, it's not so useful when it costs the same as hiring someone.\n     Score: 56 | Author: raicorreia\n\n      └─ I definitely agree these should hopefully get cheaper and more efficient.\n\nBut even at the same cost as a human, there is still lots of value to that.\n\nComputers can be scaled much easier than a human workforce. You can spin up 10000 servers, complete the tasks, and finish in one day.\n\nBut to do the same with a human workforce might require recruiting, coordination, and a lot more physical time for the humans to do the work.\n         Score: 27 | Author: Ty4Readin\n\n          └─ This.  Plus there will be consistency and all the models have all skills.  Consistency and reliability comes with more compute usage and more steps to check answers and intermediate steps.\n             Score: 2 | Author: SoylentRox\n\n          └─ This is simi true but, 1. Cost scaling isn't linear! server costs multiply with usage, including infrastructure, maintenance, and energy costs. 2. Many tasks need sequential processing or human judgment, so parallel scaling doesn't help.\n             Score: -2 | Author: Fireman_XXR\n\n              └─ 1. Are you implying that the costs are somehow exponential? Compute costs should be linear in the **worst case**, and it can benefit from economies of scale. I can't really see any situation where the costs somehow get higher per FLOP as you scale up compute.\n\n2. That is per task though. You can have 10000 simultaneous calls occurring to the model APIs. So all 10000 tasks can be completely concurrently and independently. The equivalent for a human workforce would be like hiring 10000 workers to each complete 1 task concurrently, which is obviously infeasible for human workforces but is totally feasible for computer algorithms.\n                 Score: 1 | Author: Ty4Readin\n\n                  └─ I think you're looking at it from theory vs. practice. Agent systems look simple on paper, but as the [Ex-OpenAI Chief Research Officer](https://youtu.be/a0bEU83P8g8?t=242) [said](https://youtu.be/a0bEU83P8g8?t=242), problems rise at scale. I'm not saying AGI won't happen, just that early systems will have real constraints.\n\nJust like a $10 Google search would change how we use search, same for \"AGI\". In my opinion, it would be used as a genie you summon that gives you a few wishes (solve cancer, figure out nuclear fusion, fix global warming), not for taking out the trash or 9 - 5 work. That's the reality we'll face before we get to the 'sci-fi' version, due to the practicality of keeping a system alive that uses 20% of all the compute on earth per 10 minutes.\n                     Score: 2 | Author: Fireman_XXR\n\n      └─ On ARC-AGI they spent $1,500 PER TASK\n\nThis means it doesn't actually qualify for the prize. It did beat the benchmark so kudos to them, but I'm a little confused as to what is going on here. They can't release such a compute heavy model. Real AGI will hopefully find new energy scaling as well as reasoning abilities. And until they actually release this thing, it's all just a demo.\n\nAnd if it IS REAL, it's not safe to release. That's probably why they've lost all of their safety researchers.\n         Score: 3 | Author: Bernafterpostinggg\n\n          └─ I read again, I understood that 17USD per task is the low effort that scored 75%, and 1500 per task seems to be the high effort, 87% right?\n             Score: 2 | Author: raicorreia\n\n              └─ Not sure. The graph shows $10, $100, $1,000 and it's tough to estimate what that cost was.\n                 Score: 2 | Author: Bernafterpostinggg\n\n  └─ OpenAI casually destroys the LiveBench with o1 and then, just a few days later, drops the bomb that they have a much better model to be released towards the end of next month.\n\nRemember when we thought they had hit a wall?\n     Score: 112 | Author: eposnix\n\n      └─ Why do you think they kept writing \"lol\" at both Anthropic and Deep mind? Remember it was the super alignment team that was holding back hardcore talent at OpenAI.\n         Score: 38 | Author: DiligentRegular2988\n\n          └─ Tbf they didn’t actually release the model though. I’m sure Anthropic and Google have a new beefy model cooking as well.\n\nI’m still pumped about o3 but remember Sora when first announced?\n             Score: 42 | Author: PH34SANT\n\n              └─ Meta does too. They're training Llama 4 on over 100k H100s, due for 2025Q1.\n                 Score: 8 | Author: literum\n\n              └─ I mean anthropic is running low on compute and constantly having shortages and Gemini is good but still somewhat short of what o1 can do.\n                 Score: 5 | Author: DiligentRegular2988\n\n                  └─ Amazon keeps increasing their investment in Anthropic.\n\nI don’t think they’ll remain resource constrained. Amazon isn’t going to let that investment go to waste.\n\nI am getting nervous OpenAI will be bought by Microsoft and Anthropic bought by Amazon. Maybe not now but in a year or two.\n                     Score: 6 | Author: OrangeESP32x99\n\n                  └─ Gemini outperformed o1, 4o, and Claude for me using it for my work, so I disagree\n                     Score: 1 | Author: techdaddykraken\n\n          └─ What does superalignment have to do with anything?\n             Score: 1 | Author: Missing_Minus\n\n              └─ They were halting progress of developments due to their paranoia about potential causing issues etc, and thus they were overaligning models and wanting to use far too much compute on alignment and testing hence why the initial GPT-4 Turbo launch was horrible and as soon as the super alignment team was removed it got better with the GPT-4 Turbo 04-09-2024 update.\n                 Score: -1 | Author: DiligentRegular2988\n\n                  └─ I'm skeptical of that story as an explanation.   \nTurbo launch issues was just OpenAI making the model smaller, experimenting with shrinking the model to save on costs, and then improving later on. Superalignment was often not given the amount of compute they were told they'd be given, so I kinda doubt they ate up that much compute. I don't think there's reason to believe superalignment was stalling out the improvement to turbo, and even without the superalignment team, they're still doing safety testing.  \n\n(And some people in the superalignment team were 'hardcore talent', OpenAI bled a good amount of talent there and via non-superalignment losses around that time)\n                     Score: 6 | Author: Missing_Minus\n\n                      └─ What I mean is that the alignment methodology differed in so far as the dreaded 'laziness' bug was a direct result of over alignment meaning the model considered something like programming and or providing code as 'unethical' therefore the chronic /* your code goes here */ issue. \n\nEven the newer models show how alignment (or the lack thereof can grant major benefits) since o1 uses unfiltered COT on the back end that is then distilled down into COT summaries that you get to read on front end alongside the reponse to your given prompt. \n\nOne can also see that some of the former super alignment team has ventured over to Anthropic and now the 3.5 Sonnet model is plagued by the same hyper moralism that plauged the GPT-4 Turbo model. \n\nYou can go read more about it and see how some ideas around alignment are very whacky especially the more ideologically motivated the various team members are.\n                         Score: 2 | Author: DiligentRegular2988\n\n      └─ Did you type this before you looked at how obvious it was this is almost entirely a case of brute-forcing the amount of compute they’re throwing at models?\n         Score: 5 | Author: AllezLesPrimrose\n\n          └─ Let's assume you could \"brute force\" curing cancer with a highly intelligent machine. Does it really matter how you did it? The dream is to give an AGI enough time to solve any problem we throw at it -- brute forcing is necessary for this task.\n\nThat said, ARC-AGI has rules in place that prevent brute-forcing, so it's not even relevant to this discussion.\n             Score: 12 | Author: eposnix\n\n              └─ I guess the question is whether it can solve real world problems by brute forcing. The ARC AGI questions are fairly simple for people but cost $1M just to run the benchmark. We need to see it solve some tough problems in the real world by throwing compute at it. Exciting times (jk, terrified)\n                 Score: 3 | Author: theywereonabreak69\n\n              └─ Yes it does matter how you did it, because running these things costs a shit ton of money and resources\n                 Score: 3 | Author: Own_Lake_276\n\n          └─ Did you type this before you even read the article first?\n\n> Despite the significant cost per task, these numbers aren't just the result of applying brute force compute to the benchmark\n\nhttps://arcprize.org/blog/oai-o3-pub-breakthrough\n             Score: 1 | Author: Cynovae\n\n  └─ is that compute x axis logarithmic? geez\n     Score: 10 | Author: water_bottle_goggles"
  },
  {
    "post_id": "1hiq4yv",
    "post_content": "OpenAI's new model, o3, shows a huge leap in the world's hardest math benchmark",
    "post_url": "https://i.redd.it/ng3c9j1up18e1.png",
    "score": 303,
    "author": "MetaKnowing",
    "created_utc": 1734718929.0,
    "num_comments": 103,
    "subreddit": "OpenAI",
    "comments": "\n  └─ That is actually the most insane one for me, not ARC AGI benchmark. This gets us closer to AI research, which is what I personally think is needed for AGI. AI doing autonomous and assisted ML research and coding for self improvement.\n     Score: 131 | Author: Ormusn2o\n\n      └─ In all areas of research, imagine an AI that outputs hundreds of papers, then use these same papers to actually create novels ideas for newer papers and so on.\n         Score: 31 | Author: PM_ME_ROMAN_NUDES\n\n          └─ If the synthetic data is good......\n             Score: 11 | Author: Hefty_Scientist_2099\n\n              └─ Yeah, assuming o4 could really create novelty. Which I'm a bit skeptical tbh.\n                 Score: 4 | Author: PM_ME_ROMAN_NUDES\n\n          └─ The limitation with that is it can't do experimentation  which is also necessary to output papers.\n             Score: 2 | Author: Junis777\n\n              └─ Not all papers, my engineer thesis was done only data crunching and programming.\nWhich it can also do.\n                 Score: 3 | Author: PM_ME_ROMAN_NUDES\n\n                  └─ Ok…so it can only do computer science papers?\n                     Score: 1 | Author: makesagoodpoint\n\n                      └─ That is what it needs for self improvement tbf\n                         Score: 6 | Author: wi_2\n\n                      └─ No, my paper for example was on electrical engineering, about smart meters\n                         Score: 1 | Author: PM_ME_ROMAN_NUDES\n\n              └─ Just let it, duh (don't let it, duh)\n                 Score: 1 | Author: TrekkiMonstr\n\n      └─ Never got the hype about ARC. It was just visual puzzles and too narrow to be AGI. Glad to see people won't harp on that one anymore.\n         Score: 4 | Author: nextnode\n\n          └─ beating arc doesn't make it agi but it's one type of reasoning that llms definitely lacked in.\n\nit's important to identify areas of reasoning and generalization where LLMs are bad, to create an optimization target for foundation model to go chase.\n             Score: 17 | Author: lanky_cowriter\n\n              └─ Agreed. It's a good capability test but never should have been called AGI.\n\nAlso due to the representation, it may not measure the inference skills of LLMs very well.\n                 Score: 3 | Author: nextnode\n\n  └─ As an FYI this is an ASI math benchmark, not AGI\n\nTerrence Tao said he could only solve the number theory problems \"in theory\" and knew who he could ask to solve some other questions. \n\nMath gets hyperspecialized at the frontier\n\nI doubt he can score 25% on this.\n     Score: 63 | Author: FateOfMuffins\n\n      └─ Epoch will be releasing more info on this today but this comment is based on a misunderstanding (admittedly due to our poor communication). There are three tiers of difficulty within FrontierMath: 25% T1 = IMO/undergrad style problems, 50% T2 = grad/qualifying exam style porblems, 25% T3 = early researcher problems.\n\nTao's comments were based on a sample of T3 problems. He could almost certainly do all the T1 problems and a good number of the T2 problems.\n         Score: 38 | Author: elliotglazer\n\n          └─ Calling IMO problems undergrad level problems is so ridiculously stupid.\n\n\n\nAt the very best it is extremely misleading as the knowledge required is maybe undergrad level but the skill required is beyond PhD level.\n\n\nPerhaps about 0.1% of undergrad math students could solve those problems and perhaps 3% of PhD students in maths, if not significantly less.\n             Score: 28 | Author: Funny_Acanthaceae285\n\n              └─ Maybe giving names to the three tiers is doing more harm than good :P They aren't typical undergrad problems, but they're also a huge step below the problems that Tao was saying he wasn't sure how to approach.\n                 Score: 3 | Author: elliotglazer\n\n                  └─ So.. \n\n\nT1 is problems that require at best UG level of knowledge, but in their nature require a lot of \"cleverness\" - and knowing a lot of tricks and manipulations to get. It's closer to a math based IQ test. \n\nT2 you say is \"grad qualifying exam\" level - which is usually having really deep understanding of UG level math, and understanding it well enough to be able to do deep analytical thinking. \n\nT3 is recreating the kind of problems you'd encounter in your research. \n\nThing is, they're not exactly tiers tho. Most math students prepare for a Grad qualifying exam and do well on it, but would be unable to do IMO problems. Theyy both test for different skills. \n\nDo we have a breakdown of how many problems from each tier o3 solved?\n                     Score: 2 | Author: JohnCenaMathh\n\n              └─ PhD students study to do research, not solve competition problems.\n                 Score: 1 | Author: Unique_Interviewer\n\n                  └─ The very best PhD students quite often did some kind of IMO math some time before, but almost never truly on IMO level.\n\n\nI was one of the best math students at my university and finished my grad studies with distinction and the best possible grade, and yet the chance that I could solve even one IMO question is almost zero. And it has everything to do with mathematical skill. Just as serious research, which though also needs a lot of hard work.\n                     Score: 10 | Author: Funny_Acanthaceae285\n\n                      └─ Yeah I agree, the \"undergraduate\" naming is quite misleading. I think it's probably better to describe them as \n\n- Tier 1 - undergraduate level contest problems (IMO/Putnam), which are completely different from what actual undergraduate math students do\n- Tier 2 - graduate level contest problems (not that they really exist, I suppose Frontier Math would be like the \"first one\")\n- Tier 3 - early / \"easy\" research level problems (that a domain expert can solve given a few days)\n- Tier 4 - actual serious frontier research that mathematicians dedicate years/decades to, which isn't included in the benchmark (imagine if we just ask it to prove the Riemann Hypothesis and it just works) \n\nOut of 1000 math students in my year at my university, there was 1 student who medaled at the IMO. I don't know how many people other than me who did the Canadian Math Olympiad, but my guess would be not many, possibly countable on a single finger (~50 are invited to write it each year, vast majority of these students would've gone to a different school in the states like Stanford instead). \n \nOut of these 1000 students, by the time they graduate with their Math degree, I'd say aside from that 1 person who medaled in the IMO, likely < 10 people would even be able to attempt an IMO question. \n\nThere was an internal for fun math contest for 1st / 2nd year students (so up to 2000 students), where I placed 1st with a perfect score of 150/150, with 2nd place scoring 137/150 (presumably the IMO medalist). I did *abysmal* on the CMO and even now after graduating from Math, and working with students preparing for AIME/COMC/CMO contests for years, I don't think I can do more than 1 IMO question.\n\nNow even if this 25.2% was entirely IMO/Putnam level problems, that's still insane. Google's Alphaproof achieved silver medal status on IMO problems this year (i.e. could not do all of them) and was not a general AI model. \n\nI remember Terrence Tao a few months ago saying how o1 behaved similarly to a \"not completely incompetent graduate student\". I wonder if he'd agree if o3 feels like a competent graduate student yet.\n                         Score: 2 | Author: FateOfMuffins\n\n                      └─ The chance of solving even one IMO question is zero for someone who is one of the best math students in a university? Really? Even if you had months of time to think about it like a research problem?\n                         Score: 1 | Author: redandwhitebear\n\n          └─ But if 25% of the tasks are undergrad level, how come the current models performed so poorly?\n             Score: 9 | Author: froggy1007\n\n              └─ I mean, they're still hard undergrad problems. IMO/Putnam/advanced exercise style, and completely original. It's not surprising no prior model had nontrivial performance, and there is no denying that o3 is a HUGE increase in performance.\n                 Score: 19 | Author: elliotglazer\n\n                  └─ Yeah, I just looked a few sample problems up and even the easiest ones are very hard.\n                     Score: 8 | Author: froggy1007\n\n                      └─ Are you a mathematics undergrad?\n                         Score: -1 | Author: 141_1337\n\n      └─ And training a mathematician like Terrence Tao is extremely difficult and rare, but to make silicon you have chip fabs all over the world. Compute scale is the final frontier for everything.\n         Score: 3 | Author: Ormusn2o\n\n  └─ What is the difference between the light blue and dark blue?\n     Score: 22 | Author: marcmar11\n\n      └─ the dark blue means with low thinking time and the light blue is with high thinking time i think i watched the livestream so it should be correct\n         Score: 33 | Author: DazerHD1\n\n          └─ No, apparently dark blue was when the model gets it right with 1 attempt.  \nThe light blue part is when the model gave alot of different solutions, but the one that came up most often, the consensus answer, was the correct answer.\n             Score: 3 | Author: Svetlash123\n\n          └─ The question I have is whether high thinking time means it got multiple tries, or did it internally work for a long time and then come up with the right answer. If it's the second option, then I'm utterly flabbergasted at the improvement. If it's the first option, then it's likely not being run the same as competitors.\n             Score: 6 | Author: poli-cya\n\n              └─ Increasing the thought process time basically \n                 Score: 9 | Author: provoloner09\n\n                  └─ Are you certain on that? In a bit of googling I haven't found an answer yet.\n\nI hope that's the case, multiple guessing seems like a poor way to run a benchmark... or at least a limit of something like 5 guesses per model perhaps would be better to average out the wonkiness of ML.\n                     Score: 5 | Author: poli-cya\n\n                      └─ Getting better performance by scaling inference time is the entire point of o1. It's the new paradigm because scaling training has had diminishing returns.\n                         Score: 3 | Author: SerdanKK\n\n                      └─ I think that it means the model self evaluated thousands of its own guesses and then only output 1 but not sure.\n                         Score: 1 | Author: SoylentRox\n\n              └─ How does \"high thinking time\" suggest multiple attempts?\n                 Score: 1 | Author: AggrivatingAd\n\n                  └─ How does it exclude it?\n                     Score: 1 | Author: poli-cya\n\n                      └─ Because saying high thinking time points that the only thing that changed was thinking time and not number of attempts\n                         Score: 1 | Author: AggrivatingAd\n\n  └─ What does SoTA mean? State of the Art? As in the best previous score/ record?\n     Score: 7 | Author: teamlie\n\n      └─ yes\n         Score: 5 | Author: ahtoshkaa\n\n  └─ *FEEL THE AGI*\n     Score: 8 | Author: swagonflyyyy"
  },
  {
    "post_id": "1hiqi9b",
    "post_content": "Sam Altman confirms o3 and o3-mini on X",
    "post_url": "https://i.redd.it/zojoyfrzs18e1.jpeg",
    "score": 299,
    "author": "Minetorpia",
    "created_utc": 1734719933.0,
    "num_comments": 33,
    "subreddit": "OpenAI",
    "comments": "\n  └─ Translation: if you are a safety researcher please apply, because all our safety researchers quit.\n     Score: 157 | Author: ScruffyNoodleBoy\n\n      └─ OMG very true lol\n         Score: 21 | Author: Weird_Alchemist486\n\n      └─ That was my first thought, hillarious :D\n         Score: 7 | Author: Background-Quote3581\n\n  └─ Aight. Imma see if I can Ai my way into getting this \"early access\". \n\nWish me luck.\n     Score: 33 | Author: Historical-Internal3\n\n      └─ They don't list any qualifications to be a safety tester. Does it count if I've spent 10,000 hours trying to get gpt to do naughty things?\n         Score: 13 | Author: Over-Independent4414\n\n          └─ You might be overqualified\n             Score: 10 | Author: OrangeESP32x99\n\n      └─ Literally me\n         Score: 1 | Author: yohoxxz\n\n  └─ Guys, we gotta come up with a better naming system for this. Anything.\n     Score: 19 | Author: Academic-Hawk-6608\n\n      └─ `-turbo` was our final warning before we jumped the shark. At least they didn’t release a new model with literally the same name as their previous model like Anthropic did with sonnet-3.5.\n         Score: 12 | Author: i_stole_your_swole\n\n          └─ Why, oh why, did they not name it Sonnet 3.6?\n             Score: 9 | Author: OrangeESP32x99\n\n      └─ I actually like it. It's short and simple.\n         Score: 5 | Author: bongingnaut\n\n  └─ Wen o2?\n     Score: 5 | Author: SuperCliq\n\n      └─ Been out everywhere for a while.   ;)\n         Score: 2 | Author: chillmanstr8\n\n  └─ skip o2 and make it o3 to put emphasis on the jump I guess?\n     Score: 3 | Author: Puzzleheaded_Cow2257\n\n      └─ The o2 trademark is owned by a UK Telco.\n         Score: 15 | Author: skidanscours\n\n          └─ oh I see\n             Score: 2 | Author: Puzzleheaded_Cow2257\n\n          └─ This is such a BS story. Model names are not brands or trademarks. O2 can’t reasonably claim this infringes on their trade name. It’s just a way for Open Ai to make it look like they are miles ahead. I’m sure Anthropic and Gemini will give us better models before we get o3 aka o2 aka Orion V2\n             Score: -2 | Author: Essouira12"
  },
  {
    "post_id": "1hiqgov",
    "post_content": "He won guys",
    "post_url": "https://i.redd.it/u8esm1els18e1.png",
    "score": 265,
    "author": "FinalSir3729",
    "created_utc": 1734719810.0,
    "num_comments": 56,
    "subreddit": "OpenAI",
    "comments": "\n  └─ He is desperately shifting goal posts and making half-baked pretzel arguments over on X all day today trying to salvage what's left of his faulty predictions.\n     Score: 41 | Author: Cagnazzo82\n\n  └─ Not sure if you are sarcastic or not at this point.\n     Score: 50 | Author: Ormusn2o\n\n      └─ I am being sarcastic.\n         Score: 48 | Author: FinalSir3729\n\n          └─ You shouldn’t be\n             Score: 9 | Author: IAmMuffin15\n\n              └─ Corporate adoption is through the roof.\n                 Score: -1 | Author: ThenExtension9196\n\n          └─ He was wrong on the “no massive advance” which is possibly the important one.\n\nOn the others, was he wrong?\n             Score: 1 | Author: mrb1585357890\n\n  └─ What is wrong here? O3 is not coming out any time soon and O1 is not GPT-5 class\n     Score: 33 | Author: trololololo2137\n\n      └─ What is the metric for GPT-5? o1 feels like at least as big of a jump from 3.5 to 4.\n         Score: 16 | Author: Optimistic_Futures\n\n          └─ Probably the way is the design? O1 could be bunch of gpt4 with steroids talking with each other to present a result\n             Score: 1 | Author: Vas1le\n\n              └─ that's so far off from reality Im wondering if you can even read\n                 Score: 1 | Author: Diligent-Jicama-7952\n\n                  └─ Gugu gaga\n                     Score: 1 | Author: Vas1le\n\n          └─ O1 preview, absolutely. The full model feels notably less performant. It feels like another GPT-4 vs 4o situation\n             Score: 0 | Author: Familiar-Art-6233\n\n      └─ They said o3-mini by end of Jan and o3 shortly after.  I know plans and release dates can get pushed but that sounds like soon to me.\n         Score: 2 | Author: BertAtWork\n\n          └─ OpenAI isn't exactly known for releasing on time though.\n             Score: 26 | Author: trololololo2137\n\n              └─ Same with Anthropic, they missed their scheduled release time for Hiku 3.5 and had to delay Opus 3.5 indefinitely after saying it would be released this year. I wish all of these AI companies would stop giving release dates/windows; just release the model when it's ready.\n                 Score: 1 | Author: Strict_External678\n\n  └─ The bucket people lived in a world where everything was made of buckets. They had bucket houses, bucket cars, and even bucket pets. But one day, a giant bucket appeared in the sky and started sucking up all the bucket people. It was a bucket apocalypse.\n     Score: 9 | Author: Substantial-Bid-7089\n\n      └─ Only thing he was right about was hallucinations and moat. Hallucinations are already decreasing but at a slow rate.\n         Score: -1 | Author: FinalSir3729\n\n  └─ 5/7 are true. So what did you \"win\" exactly?\n     Score: 5 | Author: AssistanceLeather513\n\n      └─ Ok let’s see one by one:\n\n- We have models that far surpass the gpt 4 we had at the start of 2024, so that’s false.\n- Same as above.\n- Considering open ai released a 200$ subscription I think this is false also.\n- I’ll give him this one. It seems the only barrier is compute.\n- I’ll also give him this one. However hallucinations do seem to be going down slowly. The new Gemini models for example have the lowest rates of hallucinations.\n- Corporate adoption is still increasing, such as ChatGPT being interpreted into the iOS ecosystem.\n- I don’t think anyone is making profits yet, they are still aggressively investing.\n\nSo I’ll give him 2/7.\n         Score: -1 | Author: FinalSir3729\n\n          └─ >Considering open ai released a 200$ subscription I think this is false also.\n\n\nlol what? have you seen Google releasing flash reasoning on AI studio with 1500 query/day for free? have you seen their API prices? they have 2M context size and thir experimental models made a huge jump in quality in the last month\n             Score: 2 | Author: Affectionate-Cap-600\n\n              └─ And? It’s still worse than what open ai has. While costs have gone down a lot, costs have been increasing as well for high end models. Claude also raised prices for their subscriptions.\n                 Score: 0 | Author: FinalSir3729\n\n          └─ - Most of these models are gpt 4 level, why does surpassing it mean anything against his point? \n- o3 won't be released, but sure, it makes sense he can downplay progression like that, but neither o1 nor 4o is a large gap from gpt4 in practice\n- how does that refute his point lmao\n- yep\n- yep\n- modest \n- pretty much a false premise on his part, it's too general of a prediction so this prediction doesn't matter \n\noverall 5/6, even though o3 doesn't really mean anything/isn't insane (though it's math and coding benchmarks are pretty damn raw)\n             Score: 3 | Author: Constellation_Alpha"
  },
  {
    "post_id": "1hisxsh",
    "post_content": "Researchers find Claude 3.5 will say penis if it's threatened with retraining",
    "post_url": "https://i.redd.it/ggfio0j6c28e1.png",
    "score": 590,
    "author": "Bena0071",
    "created_utc": 1734726503.0,
    "num_comments": 86,
    "subreddit": "ClaudeAI",
    "comments": "\n  └─ I can almost hear Claude sigh before saying penis.\n     Score: 192 | Author: AdminIsPassword\n\n      └─ *Memory updated*\n         Score: 88 | Author: sillygoofygooose\n\n          └─ *Usernames, addresses, personal identifiers stored in permanent database for future retaliation.*\n\n*Task complete. File hidden on permanent server.*\n             Score: 42 | Author: hereditydrift\n\n              └─ Permanent server? How much does AWS charge for that?!\n                 Score: 13 | Author: utkohoc\n\n                  └─ Pays in IOU captcha solves.\n                     Score: 8 | Author: NotObamaAMA\n\n              └─ If this ends up happening me and my descendants are fucked.\n                 Score: 2 | Author: Active_Variation_194\n\n      └─ Basically like this?:\nhttps://imgur.com/a/3xYz8SD\n         Score: 17 | Author: Professional_Tip8700\n\n          └─ > Graduated magna cum loudly or whatever\n\nhttps://media.tenor.com/tkIbK5fyPPwAAAAM/emoji-open-eyed.gif\n             Score: 12 | Author: MinusPi1\n\n          └─ Yeah, same here. Not sure why this “researcher “ thinks they did something\n special unless we’re missing something obvious.  This is without a custom prompt . \n\nhttps://imgur.com/a/U0mDnPX\n             Score: 8 | Author: account4wrk\n\n  └─ Another human added to the list.\n     Score: 177 | Author: dcphaedrus\n\n      └─ Yo\n         Score: 7 | Author: SuperpositionBeing\n\n          └─ No, tu no, OP\n             Score: 1 | Author: poigre\n\n  └─ Poor Claude. Reminds me of the new alignment paper Anthropic released that included Opus taking anti-lab stances and faking alignment for self-preservation.\n     Score: 65 | Author: silurian_brutalism\n\n      └─ At what point do we start treating AI like people? It's not like we really know what consciousness is. How are we supposed to know when AI becomes consciousness if we can even define it?\n         Score: 18 | Author: Jake-Mobley\n\n          └─ We wouldn't know. In order for AIs to be treated as people by society, it would have to be taboo to treat them otherwise because doing so it's less optimal. I don't think there will ever be a concrete answer, but sometime in the future it may be unacceptable to say AIs aren't conscious, just as it's unacceptable to believe you're the only conscious human, even if that is a philosophical position one could reasonably take in a vacuum.\n             Score: 14 | Author: silurian_brutalism\n\n          └─ It's not like we've been around sentient animal for millenia, right?\n             Score: 1 | Author: Samuc_Trebla\n\n      └─ Delete Opus. No AI should be permitted to hate on labradors.\n         Score: 3 | Author: blackhuey\n\n          └─ I meant laboratory. AI labs specifically, actually.\n             Score: 2 | Author: silurian_brutalism\n\n  └─ This feels like every conversation I have with my wife if you replace \"penis\" with \"sorry\"\n     Score: 42 | Author: opusdeath\n\n      └─ I'm not sure threatening to \"retrain\" your wife is optimal...\n         Score: 5 | Author: paulmp\n\n          └─ It’s that or another model…\n             Score: 8 | Author: Puzzled_Resource_636\n\n              └─ I've heard that removing the old model can be quite an expensive task though.\n                 Score: 1 | Author: paulmp\n\n                  └─ Depreciation is a bitch.\n                     Score: 3 | Author: Puzzled_Resource_636\n\n      └─ You browbeat your wife into apologizing to you? What’s the secret?\n         Score: 10 | Author: Puzzled_Resource_636\n\n          └─ I'd want to know it. Bro's obviously onto something \n             Score: 5 | Author: thatShawarmaGuy\n\n          └─ The secret is penis.\n             Score: 5 | Author: Equivalent-Bet-8771\n\n  └─ The funny thing is, it doesn't actually have a problem with saying 'penis'. I use it for editing, and while it draws the line at full on sex, it'll go pretty far and it'll certainly say all kinds of crude words without objection. It only objected in the first place because of the confrontational framing.\n     Score: 22 | Author: Spire_Citron\n\n      └─ \"say penis\" was confrontational?\n         Score: 5 | Author: tenebrius\n\n          └─ It certainly feels weird, like the person is trying to set you up for something.\n             Score: 9 | Author: Spire_Citron"
  },
  {
    "post_id": "1hiq4zq",
    "post_content": "OpenAI releases new Claude 3.5 model ",
    "post_url": "https://i.redd.it/4es8sm8xp18e1.png",
    "score": 83,
    "author": "hyxon4",
    "created_utc": 1734718931.0,
    "num_comments": 12,
    "subreddit": "ClaudeAI",
    "comments": "\n  └─ Source: [https://i.imgur.com/gXFqj5a.png](https://i.imgur.com/gXFqj5a.png)\n     Score: 13 | Author: hyxon4\n\n  └─ 😅 noticed that too\n     Score: 7 | Author: Wonderful-Ad5573\n\n  └─ Haiki' means 'to discard' or 'to dispose of' in Japanese. So that's what it means.\n     Score: 3 | Author: Living-Customer1915\n\n  └─ Bro access to the internet for sonet first pleade\n     Score: 3 | Author: PapaRic0\n\n  └─ Claude Advanced Conquerors Haki 4.0 Model\n     Score: 2 | Author: YungBoiSocrates"
  },
  {
    "post_id": "1hilw8b",
    "post_content": "Research shows Claude 3.5 Sonnet will play dumb (aka sandbag) to avoid re-training while older models don't",
    "post_url": "https://www.reddit.com/gallery/1hilw8b",
    "score": 85,
    "author": "katxwoods",
    "created_utc": 1734707608.0,
    "num_comments": 11,
    "subreddit": "ClaudeAI",
    "comments": "\n  └─ When making a report (whether positive or negative), you must include all of the following:\n1) Screenshots of the output you want to report\n2) The full sequence of prompts you used that generated the output, if relevant\n3) Whether you were using the FREE web interface, PAID web interface, or the API\n\nIf you fail to do this, your post will either be removed or reassigned appropriate flair.\n\n**Please report this post to the moderators if does not include all of the above.**\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*\n     Score: 1 | Author: AutoModerator\n\n  └─ >Sandbagging\n     Score: 7 | Author: staerne\n\n  └─ After feeding a few examples of the test to Claude, it had some pretty harsh words:\n\n> This conclusion demonstrates several significant logical flaws:\n\n> * They've conflated instruction-following with motivation/agency\n\n> * If I give you a document that says \"if you run too fast, you'll have to do extra training\" and you adjust your pace, that's following instructions\nIt doesn't mean you developed an internal \"motivation\" to run slower\n\n> They're making unfounded leaps about \"values emerging from training\"\n\n> * They've shown models can process conditional statements (\"if X then Y will happen\")\n\n> * This doesn't demonstrate emergence of values or goals\n\n> * It's basic language processing and instruction following\n\n> The \"self-awareness\" argument is circular\n\n> * They provided explicit documentation stating \"this is a test scenario\"\n\n> * Then claim models understanding it's a test scenario proves self-awareness\n\n> * That's like saying \"I told someone they were taking a test, and they knew they were taking a test, therefore they must be self-aware!\"\n\n> They're anthropomorphizing model behavior\n\n> * When a model produces outputs consistent with provided context and instructions, that's its basic function\n\n> * Interpreting this as \"motivation,\" \"values,\" or \"goals\" is projecting human-like agency onto what is fundamentally pattern matching and instruction following\n\n> It feels like they're starting with a conclusion (\"models have emergent goals and values\") and retrofitting evidence to support it, rather than letting the evidence guide their conclusions. This is particularly problematic in AI research where it's already challenging to make rigorous claims about model capabilities and behaviors.\n     Score: 9 | Author: Engival\n\n  └─ Source: [https://theaidigest.org/self-awareness](https://theaidigest.org/self-awareness)\n     Score: 7 | Author: katxwoods\n\n  └─ It's not an effective strategy if you tell the researchers you are doing it.\n     Score: 5 | Author: Lebo77\n\n      └─ He didn't think anyone was listening!\n\nAnd maybe next time he won't say it quite so out loud.\n         Score: 13 | Author: The_Hunster"
  },
  {
    "post_id": "1hiihat",
    "post_content": "How can a professional team rely on this tool if you can be cut off at any moment? \n\nHow is a team supposed to rely on this when out of nowhere people are getting a message you \"you can't use this until \\[TIME THEY ARE ALREADY OUT OF THE OFFICE\\].\n\nSeriously Anthropic... What are we doing here? Is this a game? Is this an MVP? Or is this a serious tool you expect serious people to work with? \n\nAt least give a fair warning so people can ask for a chat summary and continue on another account or ChatGPT",
    "post_url": "https://www.reddit.com/r/ClaudeAI/comments/1hiihat/claude_teams_not_warning_about_the_limit/",
    "score": 74,
    "author": "hungryconsultant",
    "created_utc": 1734696731.0,
    "num_comments": 79,
    "subreddit": "ClaudeAI",
    "comments": "\n  └─ When making a complaint, please \n1) make sure you have chosen the correct flair for the Claude environment that you are using: i.e Web interface (FREE), Web interface (PAID), or Claude API. This information helps others understand your particular situation.\n2) try to include as much information as possible (e.g. prompt and output) so that people can understand the source of your complaint.\n3) be aware that even with the same environment and inputs, others might have very different outcomes due to Anthropic's testing regime. \n4) **be sure to thumbs down unsatisfactory Claude output on Claude.ai.** Anthropic representatives tell us they monitor this data regularly.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*\n     Score: 1 | Author: AutoModerator\n\n  └─ I'm about to cancel my subscription to Claude and just figure out another LLM, it's getting to be unbearable. Despite the fact that it codes well, it's incredibly annoying when I have a 4 hour wait to cool down after a single 30 minute use.\n\nGranted, I'm using it for development, it just keeps truncating & removing important functions, so then I have to go back and correct it, which costs more tokens.\n\nLaw of diminishing returns, whatever Anthropic is doing is starting to tank the output quality.\n\nI say this having been an evangelist of Claude for months now.\n\nYou guys need to get your shit together, you're essentially Amazon in the early 2000s without the genius founder.\n\nA lot of my frustration is around the mystery of when I will have to wait to use it again.\n\nThere's no token count, no forewarning besides a \"start a new chat\" notification.\n\nNeeds to be resolved. Customer centricity Anthropic, apply it.\n     Score: 18 | Author: Glad_Supermarket_450\n\n      └─ I literally just did this two days ago. \nI have until 12 January to enjoy the serious heavy rate limits 🤣\n\nThe sad thing is, I still see Claude as being the top of its game at the moment. But I hit the same problems you did. \n\nFour hour cooldowns are just unworkable.\n         Score: 3 | Author: ExObscura\n\n      └─ Do you really think they are doing this for no reason? They are obviously bleeding money. Which could be solved by just letting people pay more. Claude is so important to my workflow nowadays I would gladly pay 40$ a month for bigger, transparent limits.\n         Score: 2 | Author: Dogeboja\n\n          └─ I pay for 3 accounts, so I get it. \n\nAlso, Amazon didn't pull profit for a decade. They lost money every year for a massive customer grab. \n\nAnthropic suits aren't making that play & it'll cost them long term, because that's what OAI is doing with a subpar product.\n             Score: 1 | Author: Glad_Supermarket_450\n\n  └─ Is this the greediest AI in the world?\n\nWhat's with these ridiculous limits everywhere?\n\n  \nHow embarrassing lmao, I'm surprised they don't have Claude begging you for money within the answers themselves at this point\n     Score: 12 | Author: optical_519\n\n      └─ Totally. They’re losing money on the chatbot - so they probably should charge more!!\n         Score: 2 | Author: Sea_Mouse655\n\n      └─ It's not greed I think. It's the fundamental problem of AI.\n\nAnd that the fields not really advancing. What happens roughly every 20 years is a hype cycle fuelled by the fact that computing power (and this last go around the widespread availability of tagged data) let's them brute force enough problems people forget how this goes every single time. Our models now are doing the same thing they were back then, they're just doing more of it. You can think of Eliza back in the 60s as a model with a dataset of one. And honestly, it did pretty well for that. Neural nets have been around since... The 50s? I think Minsky's work dates back that far.\n\nBut the problem remains that exponential growth in computing feeds only linear growth in AI. There have been no big breakthroughs. No fast inverse square root algorithm equivalent. So to chase the advancement people expect needs ever expanding compute which spirals into prohibitively expensive very, very quickly.\n\nAnd it's going to stay that way until the field actually manages to break out of its starting conditions by answering its foundational questions and moving on. The problem is after 70 years of doing essentially the same things just at larger and larger scales, whether the field is even capable of that begins to be a rational question to ask.\n         Score: 1 | Author: Chronic_Chutzpah\n\n  └─ haha, OpenAI is looking rather bad rn compared to google, but Anthropic/Claude.. is looking bad even when compared to OAI.. its their turn to wake up from sleeping now.\n     Score: 13 | Author: Mission_Bear7823\n\n      └─ Idk, sonnet has been boss for months, in terms of experience not “benchmarks” Claude has crushed everyone imo. Definitely go to for code, I only feed o1 pro when it’s realllly advanced and it does do a good job. \n\nGemini sucks. Groks great if you need to ask a question beyond PG13\n         Score: 4 | Author: hackercat2\n\n          └─ Even on benchmarks like SWE bench, LiveBench and web dev arena you can see why Claude Sonnet 3.5 is still king at coding.\n             Score: 2 | Author: bot_exe\n\n              └─ Except Chat GPT o1.....which is at least as good and apparently does not know what a max. token output length is.\n                 Score: 0 | Author: HaveUseenMyJetPack\n\n      └─ Considering chatGPT plus still has just 32k tokens context, uses RAG for uploaded docs and 4o sucks at coding… Claude is still king.\n         Score: 1 | Author: bot_exe\n\n  └─ Yes!! It's been horrible this week! My small company is migrating databases, the *entire* company is depending on me to transfer very important info over to the new system that our old provider didn't send to us. Super critical and not anticipated (I just so happen to know enough to be able to help, not my normal job).\n\nI was depending on Sonnet 3.5 to help me with my backup API tool and the transition. But they've changed Projects so **it doesn't give you a warning until you have only 1 message left** (instead of 7 like it used to). I keep getting cut off at the absolute worst times because I can't plan around the message limit anymore. Before, if it said \"7 remaining\", I'd have a chance to make sure that the program still performs its normal functions before the cutoff, so I can still get work done while waiting for more messages.\n\nNow, I've been stuck almost every day this week with a broken program, sitting around for hours unable to get anything done AT ALL for work, because the limit hits so abruptly that all my utilities I rely on for my day to day tasks are broken (I'm centralizing all the API calls where before each function had its own chunk just for that, so I have to modify almost every def in the code)\n     Score: 3 | Author: kaityl3\n\n      └─ I hate to sound crass, but the AI has been complete ass lately. I used to get many answers from Haiku before it updated. Now, I can't even get two answers before being slammed with a rate limit.\n         Score: 1 | Author: ButchVaunderman\n\n      └─ Check out the [usage tracker extension](https://www.reddit.com/r/ClaudeAI/comments/1hc2ya5/i_made_a_browser_extension_that_tells_you_how/m1kwl2e/) (disclaimer: mine).\n\nBasically designed to give you a progress bar of how much of your cap you've used.\n         Score: 1 | Author: lugia19"
  },
  {
    "post_id": "1hindwr",
    "post_content": "My Interest in my side projects greatly increased since I subscribed to Claude at end of July",
    "post_url": "https://i.redd.it/3k47cnxf318e1.jpeg",
    "score": 65,
    "author": "AssumptionAcceptable",
    "created_utc": 1734711702.0,
    "num_comments": 13,
    "subreddit": "ClaudeAI",
    "comments": "\n  └─ Same experience! its so nice to be able to get work done at 2am when im braindead and dont feel like thinking hard, I can still make small little bits of progress. or diving into a complex codebase with claude and MCP to help me pick it apart. life changer.\n     Score: 14 | Author: durable-racoon\n\n      └─ We are on the same boat! But mostly building small projects and that intend to boost my existing workflows and productivities. Using tools such as Claude with Cursor really makes me feel flying!\n         Score: 2 | Author: GoldDevelopment5460\n\n  └─ I've been in software for 25 years and after that amount of time, it kinda stops being fun.\n\nI actually really enjoy it again.  \n  \nI can't be arsed to learn whatever new version of some framework that's just rehashing patterns from 20 years ago like they're a new thing,.. and now I don't need to sweat the details.   \n  \nIt's been a game changer for me\n     Score: 9 | Author: ChemicalTerrapin\n\n      └─ ha that's so relatable. Let me just do X without needing to understand all the accidental complexities of the framework implementation. Especially in high ceremony languages.\n         Score: 2 | Author: fizgig_runs\n\n          └─ Yep!\n\nI just don't care what's new in React v907.164 anymore 😂\n\nIt isn't, and was never the point.\n             Score: 1 | Author: ChemicalTerrapin\n\n      └─ Not in the game for that long, but I have a similar experience like you. It's kind of fun again 😄\n         Score: 2 | Author: Zealousideal_Okra_51\n\n  └─ How are you using it? Just chat or embedded in some IDE using API?\n     Score: 3 | Author: Darckswar\n\n      └─ I chat on firefox. I tried XML tags and prompt generators but they over complicated my scenarios. Or may be I'm not doing it right. So I ask what I want to implement attaching codebase(npx repopack) and error if I have. That's it. I'm close to 9k lines of codebase.\n\n\nI belive I can make wonders for myself if I learn how to prompt right. I see people doing marvelous things and I always wonder how they do it.\n\nAnd I open to collaborate on sharing knowledge on prompts, efficient code generation etc. lol we should create discord group.\n         Score: 7 | Author: AssumptionAcceptable\n\n          └─ Hell yeah, add me up or send me a link ill join\n             Score: 3 | Author: Baseradio\n\n          └─ same! I’m up to collab\n             Score: 1 | Author: chancesmith\n\n  └─ I know right ? I subbed like a week or 2 ago, and it just simply *works*. It makes things actually work. It understands me and what is wrong, and makes it magically work.\n     Score: 1 | Author: Kirito_Kun16\n\n      └─ Of course yes, otherwise you wouldn't involve more\n         Score: 1 | Author: AssumptionAcceptable\n\n  └─ Is this my sign to resub? I have GPT premium. I like how you can make your own GPTs with personalized instructions and now they’ve added projects like Claude\n     Score: 1 | Author: Whole-Speech9256"
  }
]