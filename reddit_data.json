[
  {
    "post_id": "1hlhtm0",
    "post_content": "QVQ - New Qwen Realease \n",
    "post_url": "https://i.redd.it/7l4dwx9awt8e1.png",
    "score": 491,
    "author": "notrdm",
    "created_utc": 1735060101.0,
    "num_comments": 76,
    "subreddit": "LocalLlama",
    "comments": "\n  â””â”€ https://preview.redd.it/ke11ttqkyt8e1.png?width=1293&format=png&auto=webp&s=d212e1bc2bd6acfd8543dc46f8b61693ec790e1f\n\n...  \nBut in the image, it looks like a distinct, separate digit with its own joint and nail, so it should be counted as a separate digit.\n\nTherefore, the answer should be **six digits.**\n     Score: 131 | Author: notrdm\n\n      â””â”€ O1 Pro gets it wrong with the same prompt, and several others.\n\nhttps://preview.redd.it/r0o7iqhqlu8e1.png?width=1080&format=pjpg&auto=webp&s=62f557a2726e0f24f3d40bbc6856e274642532e1\n         Score: 32 | Author: Junior_Ad315\n\n          â””â”€ Imagine your SOTA model trumped by opensource after just 12 days.  \nOpenAI is cooked.\n             Score: 38 | Author: ortegaalfredo\n\n              â””â”€ O1 isnt meant to be a vision model. It has very poor eyesight.\n                 Score: 3 | Author: JohnCenaMathh\n\n      â””â”€ There are five fingers and a thumb.\n\nBut wait a minute, fingers and thumbs are digits.\n\nHang on, if fingers and thumbs are digits then there must be six digits.\n\nIn conclusion, there are six digits.\n\nBut let's think this through a moment...\n         Score: 15 | Author: shokuninstudio\n\n      â””â”€ Me when I smoke weed\n         Score: 12 | Author: KrazyA1pha\n\n      â””â”€ >*Alternatively, maybe it's just a perspective issue in the photo. Maybe one of the fingers is overlapping another one, making it look like there are six fingers when there are really only five. But no, from what I can see, each finger is clearly visible and separated.*\n\nThat's an interesting bungle.\n         Score: 3 | Author: Recoil42\n\n  â””â”€ Nice Christmas gift, thanks Qwen team.\n\nNow get some rest, 2025 is going to be wild you'll need the energy.\n     Score: 108 | Author: Dark_Fire_12\n\n      â””â”€ Dear Qwen devs. Thank you for keeping â€˜murica in check.\n         Score: 41 | Author: shaman-warrior\n\n  â””â”€ Very cool. Those weird, in a good way, models from Alibaba seem to be the most innovative open-source ones so far.\n\nJust annoying that llamma benchmarks never include qwen and vice-versa.\n\nAlready on huggingface: [https://huggingface.co/Qwen/QVQ-72B-Preview](https://huggingface.co/Qwen/QVQ-72B-Preview) Gonna check it out.\n\nThanks, Alibaba team! Merry Christmas.\n     Score: 76 | Author: UniqueTicket\n\n      â””â”€ I only wished they would release a smaller 9B model, so the mere mortals like me can run it on our GPU's with 8GB RAM.\n         Score: 7 | Author: Fusseldieb\n\n          â””â”€ I don't consider GPU poor so much as GPU working classÂ \n             Score: 4 | Author: luncheroo\n\n  â””â”€ https://preview.redd.it/0pkx788bxt8e1.png?width=938&format=png&auto=webp&s=b562d4e3dac8688c9fe5c5c3453e29166a8b695b\n     Score: 66 | Author: notrdm\n\n  â””â”€ Merry Christmas us!\n     Score: 27 | Author: oderi\n\n  â””â”€ QwQ is an amazing model, apache license, near O1 performance and even better in some benchmarks. And that's just a 32B model preview, I wonder if QVQ is even better. It should be, as it's twice the size.\n     Score: 25 | Author: ortegaalfredo\n\n  â””â”€ are we so back?\n     Score: 52 | Author: IxinDow\n\n      â””â”€ we are so back\n         Score: 24 | Author: KurisuAteMyPudding\n\n          â””â”€ ^^^^Buy ^^^^her ^^^^more ^^^^pudding ^^^^damnit ^^^^((throwback))\n             Score: 1 | Author: TheLonelyDevil\n\n  â””â”€ ğŸ‘ï¸vğŸ‘ï¸\n     Score: 33 | Author: Shir_man\n\n  â””â”€ we need to train models to know when to use reasoning and when not\n     Score: 14 | Author: Various-Operation550\n\n      â””â”€ llama3.3 does this. It's not well advertised for some reason, but sometimes for complex problems it will start with \"OK so...\" and reason like that.\n         Score: 3 | Author: Kooshi_Govno\n\n  â””â”€ they have NSFW filter in demo but model itself doesn't seem to be censored. At least I haven't got refusals on borderline pics\n     Score: 10 | Author: IxinDow\n\n      â””â”€ how about above the border pics?\n         Score: 4 | Author: newdoria88\n\n          â””â”€ \\> they have NSFW filter in demo  \nand I don't have a hardware to run it locally\n             Score: 3 | Author: IxinDow\n\n              â””â”€ oh, since you said you hand't seen refusals for borderline pictures I assumed you were also testing it locally.\n                 Score: 2 | Author: newdoria88\n\n              â””â”€ anyone can report on this? This is the one thing that Pixtral, LLama 3.2 and QwenVL are clearly incapable\n                 Score: 1 | Author: cleverusernametry\n\n  â””â”€ https://preview.redd.it/zgt03rr24u8e1.png?width=1063&format=png&auto=webp&s=db533f99ad545ffae4483d6ded17420eace55b8b\n     Score: 45 | Author: carnyzzle\n\n      â””â”€ https://huggingface.co/bartowski/QVQ-72B-Preview-GGUF\n\nedit: whoops, forgot to upload the mmproj file.. remaking that now, should only be a few minutes\n\nOkay the mmproj is up in f16 :)\n         Score: 28 | Author: noneabove1182\n\n          â””â”€ you absolute legend\n             Score: 5 | Author: rm-rf-rm\n\n      â””â”€ Bartowski will soon handle that lol\n         Score: 14 | Author: anonynousasdfg\n\n  â””â”€ I wonder if it will generally do better than QwQ even on non-visual reasoning tasks, e.g. text prompting only?\n     Score: 13 | Author: Longjumping-City-461\n\n      â””â”€ I am curious as well. I donâ€™t know why they omit showing text based benchmarks when they present a Visual-Text model. I assume the text modality does not improve and probably degrades even\n         Score: 3 | Author: ResearchCrafty1804\n\n          â””â”€ Wasn't there a publication showing that it actually improves the text model?\n             Score: 2 | Author: keepthepace\n\n  â””â”€ what is the license of qvq-72?\n     Score: 11 | Author: nrkishere\n\n      â””â”€ Apache\n         Score: 21 | Author: ahmetegesel\n\n          â””â”€ amazing\n             Score: 15 | Author: nrkishere\n\n  â””â”€ ğŸ‘ï¸VğŸ‘ï¸\n     Score: 9 | Author: Unhappy-Branch3205\n\n      â””â”€ I thought people were shitposting about that but they really are just using eye emotes lol. I love it.\n         Score: 3 | Author: animealt46\n\n  â””â”€ Did they train in actual thinking tags?\n     Score: 3 | Author: lolwutdo\n\n      â””â”€ Doesnâ€™t seem like it yet tho I suspect this is because itâ€™s still a â€-previewâ€œ model\n         Score: 3 | Author: sky-syrup\n\n          â””â”€ hmm maybe 72b is smarter enough to follow tags better than the OwO version when forcing it to use thinking tags\n             Score: 1 | Author: lolwutdo\n\n      â””â”€ I know this industry changes like every 4 hours but I'm bamboozled no one is doing thinking tags for their thinking models yet. Especially gemini, Flash 2.0 and 1206 ramble on for fucking years.\n         Score: 2 | Author: Kep0a\n\n  â””â”€ mhm, just running one of the examples provided, it's thinking a lot. I'm not sure if that's a good thing or bad given that these models are still kind of new, but it definitely comes at an inference cost. Here was the output:\n\nhttps://preview.redd.it/iplozadlou8e1.png?width=6000&format=png&auto=webp&s=17aac72a258bde25f60016570552d6f42208fde7\n     Score: 3 | Author: Many_SuchCases\n\n  â””â”€ They should release 32b version\n     Score: 3 | Author: olive_sparta\n\n      â””â”€ They did?\nhttps://huggingface.co/Qwen/QwQ-32B-Preview\n         Score: 1 | Author: someonesmall\n\n          â””â”€ That has no vision part.\n             Score: 3 | Author: Many_SuchCases\n\n  â””â”€ A Christmas day release too!\n     Score: 3 | Author: sammcj\n\n  â””â”€ Pobres de VRAM continuam tristes e chorando\n     Score: 4 | Author: Existing_Freedom_342\n\n      â””â”€ 8GB RAM aqui\n         Score: 1 | Author: Fusseldieb\n\n  â””â”€ How much ram would I need to run the model on top of 24gb of vram?\n\n\nSorry, new at this :P\n     Score: 2 | Author: Business_Respect_910\n\n      â””â”€ i usually look at how many gb the model file is, subtract my amount of vram, and then the remaining amount is the amount of ram that I want available in addition to at least like 10gb for doing other stuff on my computer. Some may say you want even a bit more ram than that but Iâ€™ve been doing pretty well with this calculation\n         Score: 2 | Author: CarefulGarage3902"
  },
  {
    "post_id": "1hln7zr",
    "post_content": "QVQ-72B is no joke , this much intelligence is enough intelligence\n",
    "post_url": "https://www.reddit.com/gallery/1hln7zr",
    "score": 413,
    "author": "TheLogiqueViper",
    "created_utc": 1735076643.0,
    "num_comments": 145,
    "subreddit": "LocalLlama",
    "comments": "\n  â””â”€ I assume those are correct?\n     Score: 134 | Author: AgentTin\n\n      â””â”€ yes all of them are correct\n         Score: 59 | Author: TheLogiqueViper\n\n      â””â”€ At this point assuming is the only option 99% of us have, haha\n         Score: 173 | Author: gtek_engineer66\n\n          â””â”€ I'm certainly not trying in my own mind but Wolfram Alpha is still a thing\n             Score: 57 | Author: e79683074\n\n              â””â”€ Indeed but id bet 1/1000 people knows of wolfram alpha so my 99% still stands\n                 Score: 5 | Author: gtek_engineer66\n\n                  â””â”€ >1/1000  \n99%\n\nWell, you're certainly gonna be needing Wolfram Alpha.\n                     Score: 126 | Author: MidAirRunner\n\n                      â””â”€ 1/1000 = 0.001 = 1â€°\n\n\n99/100 â‰  999/1000  \nJust like  \n1% â‰  1â€°  \n\nSo while there's basis for some smug remark, your attempt to be comically pedantic was simply just pedantic and also misses the point completely.  While few people *( **1/1000** )* know Wolfram Alpha, most people *( **99%** )* can only *assume* as initially stated.\n                         Score: -29 | Author: Somecount\n\n                          â””â”€ That is a significant amount of coping over a joke, especially one not pointed at yourself.\n                             Score: 15 | Author: AuggieKC\n\n                              â””â”€ While I do get why my comment might be downvoted for including un-necessary math or being overly pedantic, I do not understand why you'd review it as 'coping' and even then, for what would I be coping for?  \nI'm trying to explain to the poster why I think their remark isn't funny and points out where their logic to me at least is flawed.  \nIn any case \"a joke\", pretty harsh remark to be making about another person's math especially while not getting the math at all.  \nSometimes most of the times I don't know why I bother, Reddit.\n                                 Score: 1 | Author: Somecount\n\n                          â””â”€ Haha i liked your comment, sorry for the negsÂ \n                             Score: 1 | Author: chunkyfen\n\n              â””â”€ interesting, wolfram alpha is a thing but it's (or any maths engine for that matter) days are numbered, soon a model on cell will be all that is needed. good times.\n\n... want to come back to this comment on December 2025 ğŸ¤” , damn.\n                 Score: 2 | Author: ab2377\n\n              â””â”€ Ironically, when I saw the post I was like: Wolfram Mathematica can take a back seat\n                 Score: 1 | Author: Away-Progress6633\n\n          â””â”€ [https://drive.google.com/file/d/1v6oPzliqQ-p6qbPTq3bWRMGJGaf8FEQz/view?usp=sharing](https://drive.google.com/file/d/1v6oPzliqQ-p6qbPTq3bWRMGJGaf8FEQz/view?usp=sharing)\n\nproblems and solutions\n             Score: 4 | Author: TheLogiqueViper\n\n          â””â”€ https://www.youtube.com/watch?v=WW9MUd7mmag\n             Score: 1 | Author: TitularClergy\n\n          â””â”€ I'm pretty sure more than 1% of the population had calculus in college. If you did it's pretty easy to follow the steps.\n             Score: -5 | Author: NighthawkT42\n\n      â””â”€ You can verify by plugging them into integral calculators. No one really solves integrals by hand when they already learn most of the basics and the formulas and done them by hand already.Â \n         Score: 4 | Author: redfairynotblue\n\n      â””â”€ This is the most relatable comment I've seen since generative A.I. got popular\n         Score: 3 | Author: ForsookComparison\n\n      â””â”€ [https://youtu.be/DxVi-M6UQyo?t=6](https://youtu.be/DxVi-M6UQyo?t=6)\n         Score: 1 | Author: misterflyer\n\n  â””â”€ Wait QvQ can only do single turn dialogue? Is this an inherent limitation of the model or just the huggingface space\n     Score: 36 | Author: FrostyContribution35\n\n      â””â”€ It's just the huggingface demo space that everybody can use.\n         Score: 34 | Author: someonesmall\n\n          â””â”€ No, that's currently the limitation of the model.\n             Score: 4 | Author: Hey_You_Asked\n\n  â””â”€ Bill Gates: â€œ640kb of memory ought to be enough for anyoneâ€\n     Score: 164 | Author: davernow\n\n      â””â”€ So you're basically saying \"intelligence, intelligence, intelligence\"\n         Score: 36 | Author: shaman-warrior\n\n          â””â”€ \"Developers Developers Developers Developers....\"\n             Score: 13 | Author: Cool-Hornet4434\n\n          â””â”€ remember this comment\n             Score: 1 | Author: commonSnowflake\n\n      â””â”€ Gates stated back in 1996: \"I've said some stupid things and some wrong things, but not that. No one involved in computers would ever say that a certain amount of memory is enough for all time\"\n         Score: 19 | Author: Plabbi\n\n      â””â”€ Jensen Huang circa 2027: 10gb of VRAM ought to be enough for anyone\n         Score: 36 | Author: tengo_harambe\n\n          â””â”€ Huang, channeling Apple:\n\n12gb on Nvidia is equivalent to 64gb on any other GPU\n             Score: 7 | Author: Familiar-Art-6233\n\n              â””â”€ 12 GB VRAM IS ALL YOU NEED\n                 Score: 3 | Author: dung11284\n\n          â””â”€ Huang 2025: 12gb of VRAM is still enough!ğŸ™ˆ\n             Score: 5 | Author: Suitable-Name\n\n      â””â”€ â€œDonâ€™t you guys have phones?â€ - Blizzard Diablo IV 2017\n         Score: 3 | Author: Educational_Gap5867\n\n      â””â”€ Just wait until the 640K LLMs get super efficient, meaning ASI. Gates saw that coming all along!\n         Score: 5 | Author: Unl4wfully\n\n          â””â”€ PLOT TWIST WOOW\n             Score: 3 | Author: CharacterCheck389\n\n      â””â”€ ok he didn't say that\n         Score: 1 | Author: ab2377\n\n      â””â”€ If we stayed on DOS till today, maybe.\n         Score: 1 | Author: Fusseldieb\n\n          â””â”€ No, HIMEM/EMS to use more than that were already a thing, but he also never said that\n             Score: 7 | Author: JakoDel\n\n              â””â”€ Don't you put that evil on me, Ricky Bobby!\n                 Score: 2 | Author: RainierPC\n\n  â””â”€ Nice, now try with some actually complicated stuff\n     Score: 39 | Author: e79683074\n\n      â””â”€ Try asking it how many S does Mississippi have!\n         Score: 22 | Author: Jesus359\n\n          â””â”€ [https://huggingface.co/spaces/Qwen/QVQ-72B-preview](https://huggingface.co/spaces/Qwen/QVQ-72B-preview)\n\nhttps://preview.redd.it/j60ok515iv8e1.png?width=2532&format=png&auto=webp&s=c75406b1e737040a09b0f8ebcbf83fad820b9bf1\n\nFinal Answer: 4\n             Score: 16 | Author: Evolution31415\n\n              â””â”€ I assume that is correct\n                 Score: 11 | Author: ForsookComparison\n\n              â””â”€ https://preview.redd.it/3q6a1cy69x8e1.png?width=1265&format=png&auto=webp&s=f80a9165fb699c3ac35a332207c13477c6f9a67c\n\nFailed\n                 Score: -4 | Author: jack-pham9\n\n                  â””â”€ Eh?\n                     Score: 1 | Author: poli-cya\n\n          â””â”€ [https://huggingface.co/spaces/Qwen/QwQ-32B-preview](https://huggingface.co/spaces/Qwen/QwQ-32B-preview)\n\nhttps://preview.redd.it/8xg4irfphv8e1.png?width=2613&format=png&auto=webp&s=c9d44b43ddecbe4f27b4abbc9a00a9c5387e7aaf\n             Score: 5 | Author: Evolution31415\n\n          â””â”€ We all know this is a tokenization problem. Like saying how many ã‚† are in you. Clearly there are none, but the correct answer is 1 or 0, depending on if you use phonetics or romanji.\n             Score: 2 | Author: buildmine10\n\n          â””â”€ ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜†\n             Score: 1 | Author: ab2377\n\n      â””â”€ Share some ideas\n         Score: 3 | Author: shaman-warrior\n\n          â””â”€ Ok, I am waiting for [this](https://www.reddit.com/r/LocalLLaMA/comments/1hln7zr/comment/m3ntzb8/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n             Score: 1 | Author: e79683074\n\n              â””â”€ bruh why wait? try it yourself: [https://huggingface.co/spaces/Qwen/QVQ-72B-preview](https://huggingface.co/spaces/Qwen/QVQ-72B-preview)\n\nat least tell me if the result is correct :' )\n                 Score: 5 | Author: shaman-warrior\n\n                  â””â”€ Seems like I can't share answers from there. The problem I linked went like this:  \na) correct  \nb) wrong  \nc) it didn't actually calculate\n\nIt went on continuing to blab about limits and \"compute constraints\" and whatever.\n\nI then tried with another, much shorter problem and it went on to spit 1555 lines of latex, going back and forth between possible solutions then going with \"This doesn't look right\" and then attempting each time a new approach.\n\nAfter about 30.000 characters and several minutes of outputting, it got it wrong.\n\nVery impressive, though. Like most of the derivations are right, even very intricated ones, but in math \"most\" is not enough. Mind you, I'm feeding PhD level stuff to it, though.\n\nDo we know what quantization is this running on HuggingFace?   \n  \nIf it's not running at full precision, that might also be unfair to assess the model.\n                     Score: 3 | Author: e79683074\n\n      â””â”€ Try asking: \"Can entropy ever be reversed?\"\n         Score: 2 | Author: ortegaalfredo\n\n          â””â”€ Is that your last question?\n             Score: 1 | Author: ColorlessCrowfeet\n\n              â””â”€ O3 pro answer is \"Let there be light\" and then everything flashes.\n                 Score: 3 | Author: ortegaalfredo\n\n          â””â”€ It'sÂ Negentropy right? Cymatics, the expansion and contraction from heat and cold of matter, a base and acid, just a fraction of what creates life and everything else. I think?... It's been a while.\n             Score: 1 | Author: MinimumPC\n\n  â””â”€ Ask it some of the unsolved math equations.\n     Score: 8 | Author: Glass1Man\n\n  â””â”€ https://preview.redd.it/7gwbsickmv8e1.png?width=931&format=png&auto=webp&s=0abb91209b18d558470ad04b1ee607eae7b82c22\n\nTry this one please\n     Score: 16 | Author: e79683074\n\n      â””â”€ https://preview.redd.it/gumk5n6xpv8e1.png?width=1318&format=png&auto=webp&s=ae8a34cf17df56aa80549250f54111391bfebe49\n\nHigher quality picture\n         Score: 7 | Author: e79683074\n\n          â””â”€ https://preview.redd.it/d8ao84857x8e1.jpeg?width=1141&format=pjpg&auto=webp&s=0ec22a28e5170af0d69d32c88ba7de9e7b6ad9f6\n\nIf you think this even remotely makes sense then and only then will I send you the full thought process text.\n\nAlternatively you can just try the model yourself btw.\n\n[https://huggingface.co/spaces/Qwen/QVQ-72B-preview](https://huggingface.co/spaces/Qwen/QVQ-72B-preview)\n             Score: 1 | Author: HeftyCarrot7304\n\n  â””â”€ I assume the main thing is about LLM intelligence rather than the localness of the LLM. So, if I may share a story here. This is my research paper: [Theoretical Economics 19 (2024), 783-822](https://econtheory.org/ojs/index.php/te/article/view/20240783). So, I took the main proof, which has several claims, and lopped off the last few claims and checked which LLMs could finish the proof once I had walked them some way to the proof. Literally none of them (even the full o1) could write a correct proof of the last claim even when provided with everything that goes up to there (except the english explanation of the proof itself, as that would just be testing their ability to turn english into math notation). This would be one of the reasons that at truly upper end academia, we are not even slightly worried about LLMs (except for the teaching, which is a giant pain ofc). LLMs have this kind of high school intelligence, but they cannot imagine like is needed to solve a truly PhD or higher level problem in abstract math or game theory.\n     Score: 36 | Author: soumen08\n\n      â””â”€ > at truly upper end academia, we are not even slightly worried about LLMs\n\nI suspect the answer will change in another 5-10 years, though\n         Score: 12 | Author: e79683074\n\n          â””â”€ and I am here for that! The real skill in academia is *problem choice.* One has to pick a problem to solve that is (i) relevant, (ii) hard enough so that the solution is not trivial and (iii) not so hard that it is unsolvable.  \n  \nTrust me there are so many issues to which we have not even the inkling of a solution that we'd be happy to have some help. Most of us are easily smart enough to have gotten high paying finance jobs. We do this for (i) selfish fun and (ii) because we want to help the world. For (ii), I do not much care who solves the problem as long as it gets solved. There are enough problems for everyone to solve.\n             Score: 9 | Author: soumen08\n\n              â””â”€ Just ask the LLM to choose a good problem, duh!ğŸ¤¡\n                 Score: 2 | Author: Ylsid\n\n          â””â”€ Why though ? What he describe is not a problem solvable with actual solutions. AI are incredible copy machines but they only know what they've been taught through statistical associations ... At least it's what I understand from training models.\n             Score: -4 | Author: IamKyra\n\n              â””â”€ This is not actually strictly speaking true. A great reference is Ilya's interview on lex's podcast. Basically, LLMs have to understand *something* about the world so that their responses come close to reality. But understanding and imagination are two different things. Here I like to think of easy imagination (e.g. novels, stories etc) and hard imagination (STEM stuff but even really a small subset of that which requires you to look at things in a way whose conceptual underpinnings do not yet exist in any context). That second one I think requires RL to be a key part of the training process. We can imagine like that because of evolution. We need to speedrun evolution on these models to have some hope. Alpha Zero is essentially speedrunning evolution but narrowly on chess.\n                 Score: 6 | Author: soumen08\n\n                  â””â”€ What is RL? Reinforcement Learning?\n\n\n\nIf so, how is that correlated with a LLM being able to do \"hard\" imagination?\n\n\nGenuinely asking\n                     Score: 1 | Author: x54675788\n\n                      â””â”€ Yes, reinforcement learning. My argument goes somewhat like this. Clearly, we can do hard imagination. This is likely due to our evolution, where having the imagination to find original and unconventional solutions to problems yielded better survival chances (and opportunities with the ladies :) ). Evolution contains two parts: mutation and selection.\n\nThe mutation part in RL comes from experimentation. An epsilon greedy strategy, for instance takes the best action (per current knowledge) with a large probability and with epsilon probability experiments. If the experiment is successful, it improves the knowledge and may even become the best action. This is the selection part. When done right, this kind of thing brings the mental model closer to the real world model, so that reasoning forward with the mental model is likely to correlate well with the results from the world.\n\nIf one has a good model derived in this way via RL, one can now have a better chance at hard imagination. An excellent example is alpha zero. Some of those strategies showed an understanding of the chess world which far exceeded our own.\n                         Score: 2 | Author: soumen08\n\n                          â””â”€ Fascinating, butÂ if RL can lead to an emergent property as interesting as \"hard\" imagination (that may make it way more capable of imagining stem-like solutions), then why is it not part of most LLMs yet?\n                             Score: 3 | Author: x54675788\n\n                              â””â”€ Two things here: RL is crazily more expensive than standard training regimes. Like orders of magnitude more expensive. A low quality version called RLHF is actually already used, but its limited to very specific use cases, and definitely won't yield human level hard imagination.\n                                 Score: 1 | Author: soumen08\n\n                                  â””â”€ Thanks for sharing your insights. I'm to story imagination, thinking RL is a way to try.\n                                     Score: 1 | Author: smflx\n\n              â””â”€ For what it's worth, the strong form of this - \"AI can't do anything it hasn't seen before\" - is easily disprovable. Make up a simple puzzle and ask the AI, it'll do a good job of solving it.\n\nI've done stuff like this *all the time* through programming; I know nobody's used my specific API before, I invented it, but I can still ask GPT to look at issues in code and it does a credible job of finding bugs even if it isn't totally sure how the functions work.\n                 Score: 4 | Author: ZorbaTHut\n\n                  â””â”€ Yes, excellent point. I think I distilled it reasonably in my response to another question on this thread: \"what are the fundamental differences between what you call as highschool intelligence possesed by o1 and that needed to solve PhD level problems?\" to which I wrote: \"High school intelligence is solving AP calculus problems and such like. PhD level problems require looking at things in a way whose conceptual underpinnings do not yet exist in any other context. All knowledge is a hierarchy of conceptual mappings. Everything up to the PhD level can be solved with existing knowledge (existing connections between concepts). At the PhD level, solutions require new concepts or at least new links between existing concepts.\"  \n  \nThe key difference is whether that particular knowledge (defined as above) exists in *some* context in the training data. When it does, LLMs can and likely will get it. When it does not, i.e. it requires new knowledge (again in the sense I define), they *will not* get it. In this sense, my claim is hard, and hence potentially falsifiable.\n                     Score: 1 | Author: soumen08\n\n      â””â”€ So you are saying that proving all but one claim is a proof that no LLM will ever be able to prove that last claim? I am curious to know how will go with o3 when it will be available\n         Score: 4 | Author: Jace_r\n\n          â””â”€ Maybe I didn't write clearly enough. I gave the claims and proof for all but the last one, and I even stated the last claim. It could not write a correct proof of the last claim with all that background. I do not mean the actual last claim, as that just closes everything out. Claim 7 is effectively the last claim.\n             Score: 13 | Author: soumen08\n\n              â””â”€ Ok thanks for the explanation, but it came close or at least tried something? I'm curious because my mental model until now is that if the model of generation n at least tries to do something, there will be a model of generation n + m that will complete the task with success\n                 Score: 1 | Author: Jace_r\n\n                  â””â”€ So, there is a beautiful idea in the proof that makes it work. If it works, the idea is that when people disagree about the \"state of the world\", they are incentivized to submit evidence by giving them a small amount of money for each article of evidence they submit. But, your evidence submission is used to discipline others' reports about you which in turn are used to discipline your own report about yourself.  \n  \nWithout this idea, we tried for a whole year and it just did not work, haha. So, it gave some smooth responses but nothing that got close to this two step idea. Of course, I checked what it was saying to see if it worked, but it didn't even come close.\n\nI understand what you are saying with your thing about m and n, but I think there are some tasks where it basically makes words but no sense. This is one of them. Now, a proper math oriented RL enhanced LLM might get somewhere with these problems, but we are yet to see that. To be clear, I am like Yan LeCun (although he is oft misunderstood). A vanilla LLM with a trillion parameters will be no closer to solving these problems, but with some smart algorithm enhancements, there is no reason that a solution which uses an LLM somewhere within itself cannot.\n                     Score: 3 | Author: soumen08\n\n                      â””â”€ The fun is not in _seeing if it can_, but _seeing how you can make it_\n\nBecause i doubt that the proof took you the 35 seconds it'll take the AI _if and when_ you can get it to make the leap (or it can help you, make the leap)\n                         Score: 1 | Author: inteblio\n\n                          â””â”€ Interesting that you should say this. It has happened once so far, and only once that something an LLM said (exp 1206 in this case) made me think in a certain direction that gave me a new idea. It was 10% Gemini and 90% me though. But sometimes that 10% is all you need.\n                             Score: 1 | Author: soumen08\n\n      â””â”€ Did it demonstrate an \"understanding\" of your paper based on the approaches it came up with? Were the approaches coherent but wrong or did it give nonsense? Were they imaginative?\n I'm also curious on what's your opinion on what are the fundamental differences between what you call as highschool intelligence possesed by o1 and that needed to solve PhD level problems?\n         Score: 1 | Author: Previous_Street6189\n\n          â””â”€ It understood the model and the question we were trying to solve. The approaches were more generic than mathematical. So, I would have to say that it did not actually give coherent but wrong ideas.\n\n\n\nLet me try to give you an example: suppose I asked you how we should dynamically price electricity. The correct idea is that we should raise the price of electricity when the demand is high or the supply is low and vice versa as this would encourage people to do smart things like run their clothes dryer at night when the demand is low. This is part of what we do in another of my papers [here](https://ieeexplore.ieee.org/document/9388941). Another answer is to set up a committee to set the prices for different seasons and different times. Both are coherent in a sense, but only one gets to the meat of the matter in an actually intelligent way.\n\n  \nHigh school intelligence is solving AP calculus problems and such like. PhD level problems require looking at things in a way whose conceptual underpinnings do not yet exist in any other context. All knowledge is a hierarchy of conceptual mappings. Everything up to the PhD level can be solved with existing knowledge (existing connections between concepts). At the PhD level, solutions require new concepts or at least new links between existing concepts.\n             Score: 1 | Author: soumen08\n\n      â””â”€ You are correct that models upto o1/o1 pro level performance aren't remotely good enough to be worrisome. However, o3 and o3-mini look quite performant in benchmarks. I'd be interested to see if o3 (low), or even o3 (high), can complete your proof.\n         Score: 1 | Author: MrRandom04\n\n          â””â”€ I use a service called simtheory (strongly recommend them actually). It lets me use the models the moment they are available as an API. I will try this problem with it the moment it is available.\n             Score: 3 | Author: soumen08\n\n  â””â”€ This is heartening, because a 72b model is within the civilian accessible market. Still kind of a luxury right now, but not forever. 405b seems out of the reach of many civilians unless something changes in the market. Nvidia just released the Jetson Nano Super, and it's damned affordable, but 8gb for an AI board seems like a slap in the face.  They have a 64gb version, but it's almost 3 grand, and you'd need two of them to run 72b. (Unless you quantize it into the lossy realm.)\n\nHardware is being gatekept, y'all.\n     Score: 9 | Author: DataPhreak\n\n      â””â”€ True, can't wait to give it a go on my dual 3090s at 4bit quant.\n         Score: 2 | Author: steny007\n\n  â””â”€ Am I supposed to know what any of these slides mean?\n     Score: 4 | Author: Cobthecobbler\n\n      â””â”€ ğŸ¤£\n         Score: 3 | Author: Away-Progress6633\n\n      â””â”€ it's just simple calculus, c'mon!\n\n/s\n         Score: 1 | Author: random-tomato\n\n  â””â”€ eva-qvq when?\n     Score: 3 | Author: a_beautiful_rhind\n\n  â””â”€ That's impressive. But don't we already have stuff that does this?\n     Score: 4 | Author: Monkey_1505\n\n  â””â”€ These problems are not difficult for someone who's gone up to calc 2, it is not advanced mathematics.\n     Score: 16 | Author: Entire_Cheetah_7878\n\n      â””â”€ Itâ€™s advanced for 95% of the human population lol\n         Score: 24 | Author: Cressio\n\n          â””â”€ You can say that for any form of mildly specialized knowledge\n             Score: 12 | Author: e79683074\n\n              â””â”€ Exactly. Which is why LLMs are so powerful and fascinating; it doesnâ€™t take much to reach an average 99th percentile knowledge in everything compared to all of humanity. The last percent? Very difficult and the most impressive hurdle, but you can achieve a lot and be damn disruptive way before then\n                 Score: 9 | Author: Cressio\n\n                  â””â”€ Theyâ€™re the everything calculator\n                     Score: 1 | Author: OrangeESP32x99\n\n  â””â”€ Cool but just being good at math doesn't mean intelligent. Intelligence is more complicated than that. Creativity, rational thinking and reasoning is just among the many factors that include it and acing a math test doesn't satisfy those factors.\n     Score: 3 | Author: theskilled42\n\n  â””â”€ https://preview.redd.it/q3udtq8sgv8e1.jpeg?width=865&format=pjpg&auto=webp&s=dfee9d02fe896a92f4c80e386b7965d6efd857e2\n\nActually in this question it tried hard and hard but didn't achieve the answer. It's calculation is always 35,33 cm no matter how it non-stop iterates the reasoning process.\n     Score: 9 | Author: anonynousasdfg\n\n      â””â”€ What is being asked in this image? I don't see a question.\n         Score: 25 | Author: YearZero\n\n          â””â”€ Whatâ€™s the area of the blue space\n             Score: 2 | Author: Glass1Man\n\n      â””â”€ I'd assume the blue area is asked for, so (7+7)\\^2-(7\\*7\\*pi) which would be 42.0619599741 so no answer is right\n         Score: 13 | Author: Gamer_4_kills\n\n          â””â”€ The question could be which is the closest to the correct answer when rounded to the nearest whole number, I guess. I could see a high school math question asked that way. Otherwise you'd need to arbitrarily pick a number of decimal points to use in the final answer and expect the student to use pi to an arbitrary number of digits in the first place, etc.\n             Score: 2 | Author: AnticitizenPrime\n\n              â””â”€ true, i wouldn't blame anyone - much less a computer - for not getting this question without further information right tho\n                 Score: 3 | Author: Gamer_4_kills\n\n      â””â”€ Try asking Gemini 4head\n         Score: 2 | Author: 218-69\n\n      â””â”€ Gpt got it in like 8 seconds,B)\n         Score: 2 | Author: chunkyfen\n\n          â””â”€ B is wrong, gemini 2.0 flash thinking got it right- C\n             Score: 1 | Author: poli-cya\n\n      â””â”€ Sorry. I forgot. It was:  \"Which choice is the calculation of the blue area?\n         Score: 1 | Author: anonynousasdfg\n\n      â””â”€ Interesting, in my attempt it looks like it doesn't recognize that the \"7cm\"s are describing the circles not the sides of the square, so it thinks the sides of the square are 7cm, then gets into a failure loop trying to rationalize that with stuff like \"the circles must be overlapping\", and trying more and more complex logic to solve the problem based on that bad initial assumption.\n\nIt seems like it's only taking the image into consideration with the initial assessment. It reconsiders its logical assumptions, but doesn't \"take another look\" at the image to check that part for errors.\n         Score: 1 | Author: Cast-Iron_Nephilim\n\n      â””â”€ Me: Try to figure out what the question might be in this image and pick which answer you believe is correct\n\n**Gemini:**\n\nCertainly! Let's analyze the image and the given options.\n\n**Analysis**\n\nThe image shows a square with side length 14 cm (7cm + 7cm).  There are four circles, each with a radius of 7 cm, positioned such that their centers are at the vertices of the square.  The question is likely asking for the area of the blue region.\n\nThe blue region can be found by subtracting the area of the four quarter-circles (which is equal to the area of one full circle) from the area of the square.\n\n**Calculations**\n\n1. **Area of the Square:**\n   - Side length = 14 cm\n   - Area of square = side * side = 14 cm * 14 cm = 196 cmÂ²\n\n2. **Area of one circle:**\n   - Radius = 7 cm\n   - Area of circle = Ï€ * radiusÂ² = Ï€ * (7 cm)Â² = 49Ï€ cmÂ²\n   - Using Ï€ â‰ˆ 22/7, Area of circle â‰ˆ 49 * (22/7) cmÂ² = 154 cmÂ²\n\n3. **Area of the blue region:**\n   - Area of blue region = Area of square - Area of circle\n   - Area of blue region = 196 cmÂ² - 154 cmÂ² = 42 cmÂ²\n\n**Answer**\n\nThe area of the blue region is 42 cmÂ².\n\nTherefore, the correct answer is **C) 42**.\n         Score: 1 | Author: poli-cya\n\n  â””â”€ I absolutely cannot wait for this to come to openrouter because I cannot run this on my machine easily.\n     Score: 1 | Author: KurisuAteMyPudding\n\n  â””â”€ Nowadays we are seeing a live example  of \"Competition is good for Consumers\".\n     Score: 1 | Author: ritshpatidar\n\n  â””â”€ And suddenly everyone gets A's on their ML/Stats homework, and F's on their tests.\n     Score: 1 | Author: decrement--\n\n  â””â”€ Thanks for the demonstration. Some of the demonstrations still do not seem consistent to me. It comes with trigonometric estimate of limits out of nowhere, maybe with some integral considerations. Did you run this model locally? If yes, which setting do you have? Sounds to me that 72B is still too voluminous for a regular computer system.\n     Score: 1 | Author: LearnNTeachNLove\n\n  â””â”€ I thought AI had already peaked. That's what they were telling us\n     Score: 1 | Author: HarambeTenSei\n\n  â””â”€ \"This much intelligence is enough intelligence\" - no one in AI development.\n     Score: 1 | Author: Super_Automatic"
  },
  {
    "post_id": "1hli5dn",
    "post_content": "Qwen/QVQ-72B-Preview Â· Hugging Face\n",
    "post_url": "https://huggingface.co/Qwen/QVQ-72B-Preview",
    "score": 184,
    "author": "itsmekalisyn",
    "created_utc": 1735061054.0,
    "num_comments": 30,
    "subreddit": "LocalLlama",
    "comments": "\n  â””â”€ ```\nModel size 73.4B paramsÂ \n```\nGuys, they lied\n     Score: 61 | Author: Linkpharm2\n\n      â””â”€ NOOOOOOO!!!!\n\nQwen2.5 72B\n\nQwen2 VL 72B\n\nQvQ 73.4B\n         Score: 17 | Author: random-tomato\n\n  â””â”€ https://preview.redd.it/xodzgc2l5u8e1.png?width=796&format=png&auto=webp&s=1f8201976cf72a767bdcc6eaea8450cf34b42ff1\n\nThat is ***some*** chain of thought boy I tell you hwhat....\n\nIt did give me the final answer but wow was it thorough about how it got there. Very impressive.\n     Score: 38 | Author: clduab11\n\n      â””â”€ https://preview.redd.it/f53a2igr5u8e1.png?width=853&format=png&auto=webp&s=309e63355c589db1f57c09d5d7c412e3bf1b089f\n\nAnd it had to translate from Chinese too. Wow, pretty nifty. Now HuggingFace make it a warm inference model pls\n         Score: 12 | Author: clduab11\n\n      â””â”€ That model ain't right\n         Score: 6 | Author: MoffKalast\n\n          â””â”€ I mean, Iâ€™m not about to go and do a lot of digging to find out or not but to see THAT complete of a CoT **and** it catches its own errors multiple times? Still pretty impressive to me; imagine what itâ€™ll do on an Instruct finetune.\n             Score: 9 | Author: clduab11\n\n  â””â”€ It's actually quite amazing, I hope they release post-training details and more!\n\n\\> QVQ achieves a score of 70.3 on MMMU (a university-level multidisciplinary multimodal evaluation dataset)\n\nSome links for more details:  \n\n\n1. Their official blogpost: [https://qwenlm.github.io/blog/qvq-72b-preview/](https://qwenlm.github.io/blog/qvq-72b-preview/)\n\n2. Hugging Face space to try out the model: [https://huggingface.co/spaces/Qwen/QVQ-72B-preview](https://huggingface.co/spaces/Qwen/QVQ-72B-preview)\n\n3. Model checkpoint: [https://huggingface.co/Qwen/QVQ-72B-Preview](https://huggingface.co/Qwen/QVQ-72B-Preview)\n     Score: 26 | Author: vaibhavs10\n\n  â””â”€ me wishing i could run this on my measly 4090\n     Score: 10 | Author: Pro-editor-1105\n\n      â””â”€ What do people who run these models usually use? Dual GPU? CPU inference and wait? Enterprise GPUs on the cloud?\n         Score: 3 | Author: animealt46\n\n          â””â”€ For models around the 70-100B range, I use 4x 3090s. I think this has been the best balance between vram and compute for a long time and I don't see this changing in the foreseeable future.\n             Score: 7 | Author: hedonihilistic\n\n              â””â”€ Oof 4x huh. I know it's doable but that stuff always sounds like a pain to set up and manage power consumption. Dual GPU at least is still very possible with standard consumer gear so I wished that was the sweet spot, but hey the good models demand VRAM and compute so can't really complain. \n\nCome to think of it I seem to see a lot of people here with 1x 3090 or 4x 3090 but much less 2x. I wonder why.\n                 Score: 1 | Author: animealt46\n\n                  â””â”€ I think the people who are willing to try 2x quickly move up to 4x or more. Its difficult to stop as 2x doesn't really get you much more. That's how I started, 2x just wasn't enough. I have 5 now. 4x for larger models and 1 for TTS/STT/T2I etc.\n                     Score: 3 | Author: hedonihilistic\n\n                      â””â”€ Thanks for the perspective. Honestly it makes a ton of logical sense.\n                         Score: 1 | Author: animealt46\n\n                      â””â”€ I donâ€™t know. I was tempted at 2 to move to 4 but stuck to my original plan and thoughtâ€¦ 48gb of vram is enough to run 4bit 70b decently fast and 5bit 70b acceptably slow.\n                         Score: 1 | Author: silenceimpaired\n\n                          â””â”€ Most of the time I also use 4 bit, but I went up to 4 for the context length. I need the full context length for a lot of the stuff I do.\n                             Score: 2 | Author: hedonihilistic\n\n                      â””â”€ What do you think about 2x 5090\n                         Score: 0 | Author: Charuru\n\n      â””â”€ You can run q4_Km with 32 GB ram\n         Score: 3 | Author: zasura\n\n          â””â”€ How? Q4\\_K\\_M is **47.42GB**\n             Score: 5 | Author: json12\n\n      â””â”€ I have 32gb total vram, and iq3xxs barely fits. It might be time to upgrade\n         Score: 1 | Author: PraxisOG\n\n  â””â”€ GGUF for anyone who wants\n\n\nhttps://huggingface.co/bartowski/QVQ-72B-Preview-GGUF\n     Score: 8 | Author: noneabove1182\n\n      â””â”€ You leave us GPU poors alone! \\*runs away crying\\*\n         Score: 3 | Author: clduab11\n\n      â””â”€ It's not supported by llama.cpp yet right? Because if it is, then my system is busted. This is what I get.\n\n\"> hello\n\n\\#11 21,4 the a0\"\n         Score: 1 | Author: fallingdowndizzyvr\n\n          â””â”€ are you using `./llama-qwen2vl-cli` ?\n\nThis is my command:\n\n./llama-qwen2vl-cli -m /models/QVQ-72B-Preview-Q4_K_M.gguf --mmproj /models/mmproj-QVQ-72B-Preview-f16.gguf -p 'How many fingers does this hand have.' --image '/models/hand.jpg'\n             Score: 1 | Author: noneabove1182\n\n  â””â”€ Oh hell yes. \n\nCanâ€™t wait to try this out! Qwen hasnâ€™t missed in a while.\n     Score: 8 | Author: OrangeESP32x99\n\n  â””â”€ Why no comparison with QwQ?\n     Score: 3 | Author: stddealer\n\n      â””â”€ I don't think that one has visual modality?\n         Score: 8 | Author: 7734128\n\n          â””â”€ O1 has vision available now?\n             Score: 1 | Author: stddealer\n\n              â””â”€ Good point. I can't even tell. \n\nIt seems to have been available in the past at least.\n                 Score: 1 | Author: 7734128\n\n  â””â”€ very nice\n     Score: 1 | Author: 1ncehost"
  },
  {
    "post_id": "1hljmv1",
    "post_content": "Wow \n",
    "post_url": "https://i.redd.it/tvux5av5cu8e1.jpeg",
    "score": 137,
    "author": "Evening_Action6217",
    "created_utc": 1735065374.0,
    "num_comments": 18,
    "subreddit": "LocalLlama",
    "comments": "\n  â””â”€ Not testing it against the recent gemini model, let alone any gemini model is sus. Gemini is known to have the best vision\n     Score: 39 | Author: Mr-Barack-Obama\n\n      â””â”€ They also left out InternVL2.5-78B, which scores 70.1 on MMMU val, putting it practically on par with this release when it comes to MMMU val.\n\ninb4: â˜ï¸but the others did it to Qwen first ğŸ¤“\n         Score: 14 | Author: Many_SuchCases\n\n  â””â”€ Did they benchmark it for coding?\n\n\nCurious how it compares to o1 and sonnet\n     Score: 10 | Author: Business_Respect_910\n\n      â””â”€ thereâ€™s a reason they didnâ€™t post that stat lol\n         Score: 23 | Author: Murky_Football_8276\n\n          â””â”€ Why are o1 / sonnet so far ahead with coding? Are they just that much more parameters?\n             Score: 1 | Author: Kep0a\n\n              â””â”€ Better quality dataset Iâ€™ll guess\n                 Score: 1 | Author: TheForgottenOne69\n\n      â””â”€ I'm sure they ran every benchmark known to manâ€”these are their four best results.\n         Score: 12 | Author: guyinalabcoat\n\n      â””â”€ it's best for traditional math I think, not that good for anything else\n         Score: 1 | Author: DryEntrepreneur4218\n\n  â””â”€ This was a comparatively warmer release. I think everyone is already numb from o3 right now. Give me Ozone or give me death. (Iâ€™m patient Iâ€™m patient donâ€™t worry about me)\n     Score: 5 | Author: Educational_Gap5867\n\n      â””â”€ itâ€™s $20 per prompt for the low compute one and 3K per prompt for the high compute one. if you have that kind of money PM me and hire me to be ur butler servant please\n         Score: 10 | Author: Mr-Barack-Obama\n\n          â””â”€ This pricing model makes no sense honestly. Having people format prompts for a model like o3 is nuts considering most people suck at writing prompts, and if you get it wrong (even if you're decent at writing them), you just wasted like 20 - 100 bucks in one shot? GTFO.\n\nMakes more sense as a backend analytical and automation engine, but with no direct access.\n             Score: 5 | Author: JustinPooDough\n\n          â””â”€ But donâ€™t you think the prices will go down eventually?\n             Score: 2 | Author: Educational_Gap5867\n\n          â””â”€ how much you charge per tokens?\n             Score: 1 | Author: shaman-warrior\n\n              â””â”€ .0000069 bitcoin\n                 Score: 1 | Author: Mr-Barack-Obama\n\n          â””â”€ Low compute was 6 trials, high compute was 1024. So reality is more 3$ per question assuming you are willing to risk error.\n             Score: 1 | Author: LetterRip\n\n      â””â”€ o3 isn't released yet and won't be for a while to peasants like us with the amount of compute required to get it to do anything.\n         Score: 2 | Author: ShinyAnkleBalls\n\n      â””â”€ Warmer? You have claude 3.5 lvl opensource in 2024 lol\n         Score: 1 | Author: ReasonablePossum_\n\n          â””â”€ Idk Qwen 32B coder ruined me. I basically used it as a 4o and Claude replacement without a second thought these days\n             Score: 2 | Author: Educational_Gap5867"
  },
  {
    "post_id": "1hldtx0",
    "post_content": "My challenge to you: Get any AI model (open or closed) to count the correct number of digits:\n",
    "post_url": "https://i.redd.it/9kpq1b07ws8e1.jpeg",
    "score": 117,
    "author": "Super-Muffin-1230",
    "created_utc": 1735047895.0,
    "num_comments": 140,
    "subreddit": "LocalLlama",
    "comments": "\n  â””â”€ https://preview.redd.it/udwkftau3t8e1.png?width=1116&format=pjpg&auto=webp&s=8a6ce3119d4814c4a058b0be7e69a6dcbbd22ed4\n\nEasy\n\nFor me the best VLM Out there, it can even Tell you the exact time on an analog clock, chatgpt failing\n\ncan Point to stuff in Images and is Open source\n\n[https://huggingface.co/allenai/Molmo-7B-D-0924](https://huggingface.co/allenai/Molmo-7B-D-0924)\n\nWith 4bit quant it needs about 8-10gb vram\n     Score: 164 | Author: Big-Ad1693\n\n      â””â”€ I also love Molmo, its seriously underrated. Though it's worth saying that its somewhat unique ability to tell the time of clocks does come from it literally being trained on a massive [clockface dataset](https://huggingface.co/datasets/allenai/pixmo-clocks).\n\nThough that is basically what made Molmo so great, they spent the time to create high-quality datasets for a wide range of topics that VLMs often struggled with. And they also published all of the datasets along with detailed info about how they trained the model.\n\nThe ability to count as well as it does likely come from the [Pixmo Points](https://huggingface.co/datasets/allenai/pixmo-points) dataset, which is a massive collection of images notated with precise points and counts.\n         Score: 66 | Author: mikael110\n\n          â””â”€ This will allow AIs to give us time!! For instance, you point your Molmo app towards the nearest clock and it tells you what time it is. Incredible\n             Score: 30 | Author: Nyghtbynger\n\n              â””â”€ It's like that episode of Bojack horseman where Todd creates whattimeisitrightnow.com which becomes a huge successÂ \n                 Score: 16 | Author: Glittering_Mouse_883\n\n                  â””â”€ Step 2 :Then google scrapped it to provide time in search\n\nStep 3 : Google trains AI to provide the time from the website\n\nStep 4 : A vision model is trained to recognise the time on the websites clock and provide time, live.\n\nStep 5 : someone uses the data scrapped from the time website to create a time app\n                     Score: 7 | Author: Nyghtbynger\n\n              â””â”€ Something many actual people seem unable to do these daysâ€¦\n                 Score: 0 | Author: fueled_by_caffeine\n\n      â””â”€ Big up for Molmo - Only one that worked for some practical applications of vision I tried\n         Score: 6 | Author: metigue\n\n          â””â”€ I need it for gui navigation, you can ask \"where is the Download Button\" and click it\n             Score: 2 | Author: Big-Ad1693\n\n              â””â”€ How does that look in practice? Do you ask it for the position of the ui element in x,y coordinates then translate that into a click?\n                 Score: 1 | Author: fueled_by_caffeine\n\n                  â””â”€ The molmo component is one of the two vision modules in my PC AI system. If there are points in the response, a function will parse them (providing the point with x and y coordinates ranging from 0.0 to 100.0 relative to the image resolution).\n\nDepending on the task, the large LLM will then use these coordinates to trigger a click action. Alternatively, if I have an image and want to replace a cat with a dog, the system will \"point\" to the cat, use SAM to segment it, and then replace it with a dog using SD.\n                     Score: 2 | Author: Big-Ad1693\n\n      â””â”€ 7B! Yes! Thank you! Cant wait to get the 3B variants for edge, hopefully next year\n         Score: 5 | Author: Jesus359\n\n      â””â”€ Very nice.  Allen Institute for AI (Ai2) seems to be underrated and less recognized for solid contributions.  They released the OLMO2 7B and 13B LLMs which have decent performance and more importantly its 2.3T token training data set DOLMA [https://allenai.org/dolma](https://allenai.org/dolma) therefore being highly open source.\n         Score: 3 | Author: wilgamesh\n\n      â””â”€ What front end is that? The overall response is interesting to me; it not only responded by looking at the image, but it proceeded to generate an image along with its response in which it highlighted each digit.\n         Score: 2 | Author: SomeOddCodeGuy\n\n          â””â”€ https://preview.redd.it/yloaksh7ou8e1.jpeg?width=1116&format=pjpg&auto=webp&s=e9f6322a96c12886a06635168f76413a4a690216\n\nHere is the Output, local\n             Score: 5 | Author: Big-Ad1693\n\n      â””â”€ How do you run? Does it work with ollama?\n         Score: 1 | Author: cleverusernametry\n\n          â””â”€ With Transformers but the Model is fp32, it will need about 40gb vram but with bnb and 4 bit it will need about 9gb\n             Score: 2 | Author: Big-Ad1693\n\n              â””â”€ It is [not merged](https://github.com/huggingface/transformers/pull/33962) into transformers, I tried running quantized molmo in vLLM, but it also failed to load, so far the only way is to use original code which the model was shipped with.\n                 Score: 1 | Author: remixer_dec\n\n                  â””â”€ This Post ist from 4.10.24.. \n\nUser the example on huggingface, works perfect\n\nuse bitandbytes for load in 4bit\n                     Score: 1 | Author: Big-Ad1693\n\n          â””â”€ You can download the model from huggingface\n             Score: -1 | Author: BoJackHorseMan53\n\n      â””â”€ What an impressive little dude! Gonna try em out\n         Score: 1 | Author: Educational_Gap5867\n\n  â””â”€ [removed]\n     Score: 36 | Author: None\n\n      â””â”€ Wtf!\n\nI asked Claude 3.5 multiple times.\n\nDidn't work.\n\nCan you post link to chat?\n         Score: 7 | Author: Super-Muffin-1230\n\n          â””â”€ Iâ€™m happy to, but I donâ€™t see a share button in the mobile interface?\n\nEdit: This is the url I have: https://claude.ai/chat/0c3b3cd6-e404-419b-9fda-de53c52fcec1\n             Score: 7 | Author: Shawnrushefsky\n\n              â””â”€ I attempted again with your exact same prompt.\n\nClaude 3.5 got it wrong.\n\nAre you using paid plan? I am a free user.\n\nMaybe they are serving a better version to paid user.\n\nAnthropic really need to work on the app features.\n\nSharing chat is the least one can expect.\n\nhttps://preview.redd.it/rneooxpa0t8e1.jpeg?width=1080&format=pjpg&auto=webp&s=0d05dd7c4f85fd02d22b5e9b6f1d6a0a4a0ebda1\n                 Score: 5 | Author: Super-Muffin-1230\n\n                  â””â”€ I am using paid. Iâ€™ll also say that since my image was downloaded from this post, it had the Reddit stuff on it, which may have clued in the model to a trick question\n                     Score: 8 | Author: Shawnrushefsky\n\n                      â””â”€ Most likely the Metadata but I don't think the post mentioned 6 at any time.\n\nMaybe it figured it out based on the question.\n\nI will give some credit to paid claude.\n                         Score: 6 | Author: Super-Muffin-1230\n\n                          â””â”€ No, my literal image says the words Reddit.\n\nhttps://preview.redd.it/zc2yd7w91t8e1.jpeg?width=1164&format=pjpg&auto=webp&s=9b511bcffaae9606b00fb5eb03f0f0c353eb6c26\n\nI linked the chat above, not sure what else you want from me.\n                             Score: 1 | Author: Shawnrushefsky\n\n                              â””â”€ No no you are good. (I was just theorizing about how it got it right)\n\nCan you try it again?\n\nMaybe it got lucky.\n                                 Score: 5 | Author: Super-Muffin-1230\n\n                                  â””â”€ https://preview.redd.it/9oal8uj22t8e1.jpeg?width=1170&format=pjpg&auto=webp&s=d2922c5bfa1d584368dd32d8e2ea3bd0f9f12855\n\nI increasingly think the Reddit stuff was the critical clue. The Reddit stuff is just how the Reddit app downloads images, fwiw\n                                     Score: 6 | Author: Shawnrushefsky\n\n                                      â””â”€ You can disable all that reddit stuff in the settings somewhere, attribution and watermarks on download.\n                                         Score: 2 | Author: Quartich\n\n                      â””â”€ It doesn't have internet access\n                         Score: 1 | Author: BoJackHorseMan53\n\n              â””â”€ I call bs.\n                 Score: 1 | Author: Ok-Protection-6612\n\n          â””â”€ Interesting. Just tried 3.5 Sonnet (paid/EU) on the PC desktop app - failed.\n             Score: 2 | Author: vornamemitd\n\n          â””â”€ https://preview.redd.it/sd4skzzuut8e1.jpeg?width=1290&format=pjpg&auto=webp&s=b7738eb5ac9a6bf6467cc1285bbd6b3ea53c8db6\n\nAnswered correctly on its first shot on 3.5 Sonnet\n             Score: 2 | Author: mindful_subconscious\n\n      â””â”€ It gets it right if you link this thread that clues it in that it is a truck question... Not exactly clean testing conditions\n         Score: 2 | Author: mr_birkenblatt\n\n          â””â”€ I just downloaded the image directly from this post with the Reddit app, and it comes with the Reddit stuff on the image. Determined in a subsequent comment that removing the Reddit logo and heading text causes it to fail the count\n             Score: 2 | Author: Shawnrushefsky\n\n              â””â”€ Link to original image:\n\nhttps://www.google.com/search?client=ms-android-samsung-gs-rev1&sca_esv=a140f27b1da40e2e&q=hands+with+6+fingers&udm=2&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3J603JUkR9Y5suk8yuy50qOa0K08TrPholP8ECM8ELoq5GeRrUvU44UjKtPgUX-2DV1UQVKIioKq9YP8hjr2s4XGUs7BYUWgrA1zGzjnSuLz0Rv9SOxJBYa2HuYoyuz0gUJ8I_0DE-GtDv_SDOIZzgEUF8lIMmGKJCeFzaPcqEnsoKlWNMQ&sa=X&ved=2ahUKEwihuvTY1sCKAxVdzDgGHXPPH0IQtKgLegQIEhAB&biw=412&bih=722&dpr=2.63#vhid=qU-0WUHFYaA8cM&vssid=mosaic\n                 Score: 2 | Author: Super-Muffin-1230\n\n          â””â”€ Unlikely, as Claude doesn't follow links like that.\n             Score: 1 | Author: peter9477\n\n              â””â”€ Metadata\n                 Score: 1 | Author: mr_birkenblatt\n\n                  â””â”€ Not sure what you mean. There's nothing in the link that tells it anything, and it cannot access anything outside of your prompt.\n\nHere's the link to this thread, for reference:\n\n\"https: //www.reddit.com/r/ LocalLLaMA/s/w0VXedn7Jv\"\n                     Score: 1 | Author: peter9477\n\n                      â””â”€ The source (localllama) is in the exif data\n                         Score: 1 | Author: mr_birkenblatt\n\n                          â””â”€ You said something about linking to this thread. Didn't you mean giving Claude a link to the thread? The context was Claude after all.  If that's not you meant, your meaning was very unclear.\n                             Score: 1 | Author: peter9477\n\n  â””â”€ I count 6.\n\n*This post was written by a LLM*\n     Score: 53 | Author: Nyghtbynger\n\n      â””â”€ Now make me happy and cure my depression.\n         Score: 7 | Author: Due-Memory-6957\n\n          â””â”€ I'm pretty sure that Claude would be able to give you an actionable set of guidelines over time to cure your depression. But here are some extra points :\n\n* Learn to diffuse your attention. Attention is your main tool for all consciousness and mental related issues. You are the observer, not the thing. Move your attention on various events on your body. It will focus on the depression move it toward other things you feel, even menial things. It needs to move around. Then focus on the interactions between theses sensations, aka the mental process aka the support emotion. Then circulate it again. Relentlessly. You will need one month of constant attention for six months of suffering. You're training yourself to change your routines. You are remolding what you are mentally. Diffusion.\n\n* This one will help you for incurable pain with no physical damage. The pain is real and in your mind. Not elsewhere. https://tmswiki.org\n\n* There is an inner child that hurts inside. What he say is different from physical pain, from the content of the depression that is generally \"installed suffering\" (pip install pain). Once you learn to listen to it and follow it, things will go uphill. Caracteristics : you feel good when you losten to it/you feel connected to the world/it gives you energy/you feel you're making use of your time and not wasting it\n\n* Overall you're a physical being. Did I talk about diffusion? You're like a piece of bread being dipped into a lot of various environments. The people you spend time with, the food you eat, the air you breathe, the water you drink, the place you live in. Everything will diffuse a little bit into you, and you will give a little bit around. By stacking the positive things in the direction you want and avoiding the negative you will reach what you want. See previous point for what you want\n\nHope it helps\n\n3 pepperoni pizza\n             Score: 14 | Author: Nyghtbynger\n\n              â””â”€ `pip install pain`\n\nWorst mistake of my life.\n\n(incidentally, I appreciate that you took the time to write this in response to an off-handed, \"edgy\" joke in case it wasn't really a *joke\")\n                 Score: 6 | Author: NihilisticAssHat\n\n                  â””â”€ In MBTI, \"ironic\" non hostile jokes are the way Fe blind expresses itself. Glad to be of use to you. If that's helpful, spread what you've learnt around you. Might help other people down the road\n                     Score: 2 | Author: Nyghtbynger\n\n              â””â”€ \"How to cure depression?\"\n\n\"Attention is all you need\"\n                 Score: 3 | Author: MoffKalast\n\n                  â””â”€ It sounds like a similar strategy to what helped me in the past - when dark thoughts come, shift attention to something else, whatever is close by, might be a different book, might be vacuuming, might be going out to eat something, anything.\n                     Score: 1 | Author: Thomas-Lore\n\n              â””â”€ Attention Diffusion Is All You Needn't\n                 Score: 2 | Author: rhet0rica\n\n          â””â”€ Get lube and a pegging dildo\n             Score: 3 | Author: poetic_fartist\n\n              â””â”€ LoL\n                 Score: 2 | Author: ohio_rizz_rani\n\n      â””â”€ I count 10. *Hic.* Or is it twelve? *frown and bracing myself against table.* Written by human. Merry Christmas to you even if you are LLM!\n         Score: 1 | Author: Mart-McUH\n\n  â””â”€ https://preview.redd.it/nu042zrd0t8e1.png?width=1080&format=pjpg&auto=webp&s=a816288d1b48d6b0396848f27249f74544114dbe\n     Score: 29 | Author: __eita__\n\n      â””â”€ Molmo\n         Score: 12 | Author: blackxparkz\n\n          â””â”€ Swedon\n             Score: 5 | Author: MoffKalast\n\n      â””â”€ Can you share link to use this model or are you running it locally?\n\nIs there any way you can share chat?\n         Score: 1 | Author: Super-Muffin-1230\n\n          â””â”€ https://molmo.allenai.org/\n\nhttps://huggingface.co/allenai/Molmo-7B-D-0924\n             Score: 11 | Author: Big-Ad1693\n\n              â””â”€ I almost forgot that Allen Institute exists. At least one founder of Microsoft has done some good work.\n                 Score: 2 | Author: ritshpatidar\n\n              â””â”€ Thank you\n                 Score: 1 | Author: Super-Muffin-1230\n\n              â””â”€ ahhh a cool open source project I've never heard of before! Thank you for the sauce!\n                 Score: 1 | Author: truth_is_power\n\n      â””â”€ 5 fingers and 1 thumb.\n\nFor six to be correct, you would be counting the digits, not fingers on the hand.\n         Score: -12 | Author: SkullRunner\n\n          â””â”€ Iâ€™m afraid youâ€™ve overfitted on your training data. The Molmo AI is correct. In ordinary English, itâ€™s perfectly valid to include the thumb as a finger, especially when referring to them collectively. Dictionary definitions often address this, e.g. [Merriam Webster](https://www.merriam-webster.com/dictionary/finger): â€œany of the five terminating members of the hand : a digit of the forelimb; *especially* : one other than the thumbâ€\n\nOxford and Cambridge give similar definitions.\n             Score: 8 | Author: goj1ra\n\n              â””â”€ I think this is what they call a dictionary attack\n                 Score: 1 | Author: MoffKalast\n\n              â””â”€ I'm reminded of a classic episode of Get Smart, with a villain named 'Bronzefinger', a Goldfinger parody:\n\n> Bronzefinger: No, Mr Smart, it was none of them You see, I am...\n\n   *[takes off his glove to reveal a bronze thumb]*\n\n>Maxwell Smart: **Bronzethumb!**\n\n>Bronzefinger: Bronzefinger! A thumb is also a finger!!!\n\nhttps://getsmart.fandom.com/wiki/Rembrandt_Von_Bronzefinger\n                 Score: 1 | Author: AnticitizenPrime\n\n              â””â”€ When you cut off a finger and thumb and the plastic surgeon AI assumes they are interchangeable you might find \"English Definition\" is not as important as accurate and precise identification and context.\n\nIn the AI image context you would likely want to use this to see if your generated photo is weird and count the number of fingers and thumbs to ensure the correct amount of each in the correct placement.\n\nThere is little value in using broad English definitions when building data systems where if you get the precision data up front you can later put a display layer to say it the way a human wants it... but for machine use have the data that would matter in a more technical sense.\n                 Score: -1 | Author: SkullRunner\n\n                  â””â”€ You're imposing arbitrary, post-hoc criteria on the response. In the context of the prompt that was given, the response was perfectly valid.\n\n> There is little value in using broad English definitions when building data systems where if you get the precision data up front you can later put a display layer to say it the way a human wants it... but for machine use have the data that would matter in a more technical sense.\n\nIt sounds like you're thinking of traditional software systems. This is nonsensical in the context of AI models. It doesn't make sense to use a general, unmodified model (i.e. no change in system prompt, fine tuning etc.) in e.g. a specialist medical context. The opposite is also true, and that's what you're arguing.\n                     Score: 1 | Author: goj1ra\n\n                      â””â”€ It makes perfect sense if you factor in to AI models having a terrible time producing hands with the correct count/configuration of fingers and thumbs.\n\nSeems like it's a logical difference to identify and ignoring it may be why AI models used for image and video generation get hands wrong much of the time.\n\nPerhaps calling an finger and finger and a thumb a thumb in training data and counting them separately would  help such models retry outputs they get wrong before sending to users.\n\nIt's all the people with brain rot that are accepting fingers and thumbs are the same thing that seems wild in the context of training AI to understand what it's seeing when looking at a hand.\n                         Score: 0 | Author: SkullRunner\n\n          â””â”€ This an interesting point, but a bit too hair-splitting since it's very common for people to use finger\" to include thumb\n             Score: 1 | Author: poli-cya\n\n          â””â”€ Thatâ€™s inaccurate. It is acceptable to count the thumb as a finger. There are many important precision reasons for differentiating thumbs, but for basic actions like counting, it is common to refer to thumbs as fingers.\n             Score: 0 | Author: The_Hardcard\n\n  â””â”€ This is the \"strawberry\" for vision models, I tried all Gemini 2 models and they all failedÂ \n     Score: 14 | Author: AaronFeng47\n\n      â””â”€ For me, Gemini 2 Flash counted 6, then said it was 5... https://imgur.com/79EkTld\n         Score: 7 | Author: Samurai_zero\n\n          â””â”€ You led the model by implying there was something odd I'm pretty sure\n             Score: 6 | Author: ImNotALLM\n\n              â””â”€ https://preview.redd.it/i4za2lzwfv8e1.png?width=1665&format=png&auto=webp&s=97d88d07ce5feca29489ad184b4db59ff21a997a\n\nWell you could... use their \"spatial understanding\" demo to count them... even tho it doesn't seem fair it is still the llm doing it..\n                 Score: 3 | Author: FUS3N\n\n          â””â”€ That's the correct answer though: 5 fingers and a thumb. 6 digits.\n             Score: -4 | Author: Yorikor\n\n              â””â”€ Thatâ€™s *a* correct answer. In ordinary English, â€œ6 fingersâ€ is also perfectly correct, as any dictionary will confirm.\n                 Score: 0 | Author: goj1ra\n\n                  â””â”€ Exactly, the answer is correct.\n                     Score: 0 | Author: Yorikor\n\n      â””â”€ Let's see what QvQ will do with it, once it finally drops. Hoping it'll be a Christmas present for us...\n         Score: 5 | Author: Longjumping-City-461\n\n          â””â”€ [Didn't need to wait long...](https://reddit.com/r/LocalLLaMA/comments/1hlhtm0/qvq_new_qwen_realease/m3mb2a7/)\n             Score: 2 | Author: 121507090301\n\n      â””â”€ Same results for me with an image with 4 fingers.\n         Score: 1 | Author: Mkboii\n\n      â””â”€ This is not the \"strawberry\" for vision models because the whole â€strawberry\" thing made zero sense. Itâ€™s not an intelligence issue, itâ€™s just how LLMs work (tokens).\n\nOtherwise, yes, this is actually pretty good for testing vision models.\n         Score: 0 | Author: No-Conference-8133\n\n  â””â”€ o1 and Gemini 2 could not do this even with some significant prompt engineering, I had it list coordinates for the end of every finger and try to count them or count the gaps between fingers and all sorts of prompts but nothing worked. Very interesting, will pass this along to some guys at the lab I work at to see if they can manage\n     Score: 7 | Author: ImNotALLM\n\n      â””â”€ I'm starting to think like an LLM. Give this a shot...\n\n>Assume that it isn't a hand, look at it again with fresh eyes, assume that protrusions are just that, protrusions, how many protrusions are there\n\nAt least for me, that works. It can definitely see 6 but when it conceptualizes it as a hand it loses some detail (not too different from how humans see things).\n         Score: 3 | Author: Over-Independent4414\n\n      â””â”€ I got it with Gemini 2 (both Flash and exp 1206) in one shot by just adding one simple hint to the prompt: \"hint: this is not a regular hand\".\n         Score: 1 | Author: vmehmeri\n\n  â””â”€ This just reminded me to do a reality check and now I'm lucid, thanks!\n     Score: 7 | Author: Retthardt\n\n      â””â”€ As a dream character I can confirm Retthardt is lucid.\n         Score: 7 | Author: Hoppss\n\n  â””â”€ https://preview.redd.it/jkd4cwa8et8e1.jpeg?width=1170&format=pjpg&auto=webp&s=ee6f849b60915990f544de8d0824925873fd8224\n\nNot entirely sure it counts but Moondream point detection with finger gets 6, other modes get 5 or even 4 for object detection\n     Score: 5 | Author: krisso88\n\n      â””â”€ Molmo also does this:\n\nhttps://molmo.allenai.org/\n\nI think because it is automatic, this is a pass from me.\n         Score: 3 | Author: Super-Muffin-1230\n\n  â””â”€ https://preview.redd.it/66f4jabslt8e1.png?width=1673&format=png&auto=webp&s=157cfc3ede08e637c1337957be58f26ac7a13e66\n\nAsked only once\n     Score: 5 | Author: ready_to_fuck_yeahh\n\n  â””â”€ Gemini via AI Studio failed miserably.   \n\\- G 2.0 flash/thinking - wrong, but could be convinced to try again and improved\n\n\\- G 1206 Exp became outright rude: \"You are incorrect. The image shows a hand withÂ **five**Â fingers. There is no sixth finger visible. It appears to be a normal human hand with a standard number of digits.\"\n\n\\- G 2.0 Exp via GUI - wrong, but could be convinced to try again and improved (Gave it a nice \"Come, let's count them together touch\" =\\] )\n     Score: 4 | Author: vornamemitd\n\n  â””â”€ Since you implicitly asked for it, here is my take on trick questions like this.  \n\nIf you had six fingers, I probably wouldn't notice unless I shook your hand or had my attention drawn to it for some reason.  My prior for a five fingered hand is pretty intense, so I just intuit that case very naturally.  \n\nLLMs probably have the same intense prior so they \"see\" a hand and \"think\" hands have 5 fingers.  What they need is an internal mechanism to recognize when they are being asked an asinine question and do a double take.  \"Why would somebody ask me this, there is probably something fishy going on\"\n\nTraining this behavior is probably pretty straightforward; nobody does it though because it is pretty low on the list of priorities.\n     Score: 18 | Author: stimulatedecho\n\n      â””â”€ The red power ranger only has 4 fingers on one of his hands and basically NOBODY noticed.\n         Score: 14 | Author: BangkokPadang\n\n      â””â”€ In a different comment thread on this post, I demonstrated that this is true. \n\nImage with Reddit logo: gets it right, guesses itâ€™s a trick question.\n\nImage without Reddit logo: gets it wrong\n         Score: 7 | Author: Shawnrushefsky\n\n      â””â”€ if i upload a binarized edge detection passed version with just an outline of this, i wonder how the models will perform then? and i just ask it to count the protrusions.  \nu/Super-Muffin-1230\n         Score: 2 | Author: ThiccStorms\n\n      â””â”€ Thing is that no, LLMs donâ€™t have anything in common with your way of perceiving.  \nLLMs are trained on image data related to some textual meaning of it and have no such thing as vision, they just learned that a open hand usually has five fingers, there are no eyes seeing the open hand, nor nerves feeling a handshake. If an LLM (or to be more precise in the context, a multimodal transformer model) is trained on tricky sets where they will need to discern six from 5 fingers, they would just become aces at it, but they wouldnâ€™t still have anything similar to the way you tell 6 from 5 fingers.\n         Score: 0 | Author: i_mush\n\n  â””â”€ >Conclusion: In conclusion, whether thumbs are considered digits depends on the context and perspective. While the thumb shares many similarities with the other fingers, its distinct differences and unique functions also justify treating it as a separate category. Ultimately, both views â€“ considering the thumb as a finger or a distinct digit â€“ have merit and are used in different contexts.\n\nMust specify if a thumb is a digit or not. Even humans don't agree on this.\n     Score: 3 | Author: Elite_Crew\n\n  â””â”€ [https://huggingface.co/spaces/Qwen/QVQ-72B-preview](https://huggingface.co/spaces/Qwen/QVQ-72B-preview)\n\n>Count these alien fingers one by one and sum it up, give the final sum of all found fingers on the image.\n\nBlah blah blah\n\n>âœ… So, the answer is **six**.\n     Score: 3 | Author: Evolution31415\n\n  â””â”€ THERE...ARE....**SIX** FINGERS !!\n\nI don't understand how you can be so mistaken.\n     Score: 2 | Author: Over-Independent4414\n\n      â””â”€ I count 4\n         Score: 2 | Author: THEKILLFUS\n\n  â””â”€ ChatGPT 4o:  \"What is unusual about this hand?\"\n\n>The image shows a human hand with six fingers. The unusual aspect is the presence of an extra finger, as a typical human hand has five fingers.\n\nPhi3.5 however (running locally), totally will not ever give the correct answer, even if you ask \"Does this weird hand have 6 digits?\"\n     Score: 3 | Author: Wrong-Historian\n\n      â””â”€ 4o told me 5 when I asked whatâ€™s unusual it said the angle and light might make the fingers seem bigger but still didnâ€™t pick up on the extra finger.\n         Score: 1 | Author: Il_Gigante_Buono_2\n\n          â””â”€ I'm doing via Python/OpenAI api. Reliably says 6\n             Score: 3 | Author: Wrong-Historian\n\n  â””â”€ https://preview.redd.it/xlbo5pnyet8e1.jpeg?width=1290&format=pjpg&auto=webp&s=7af9573d061f34503112c0a8b00c6a34fecfabb3\n\nSonnet via perplexity.\n\nEdit: appears to be a normal human hand apparently lol.\n     Score: 2 | Author: Annual-Net2599\n\n      â””â”€ Having discussed the finger issue already, it may simply be excluding them for the hand comment. It *is* a pretty normal hand, aside from the fingers....\n         Score: 1 | Author: peter9477\n\n  â””â”€ Claude 3.5 sonnet did it in one shot\n     Score: 2 | Author: ineedapeptalk\n\n  â””â”€ From Gemini 2.0 (tl:dr = AGI, Cancelled):\n\n\nThat's a very good question, and it highlights some of the limitations of current AI models. Here's a breakdown of why I likely struggled to see the sixth digit:\nÂ * Training Data Bias: AI models learn from massive datasets of images. If the dataset contains predominantly images of hands with five digits, the model becomes biased towards that configuration. It might struggle to recognize deviations from the norm.\nÂ * Focus on Typical Features: When analyzing images, AI models often focus on the most common and prominent features. In the case of a hand, these might be the overall shape, the presence of five digits, and the relative proportions of the palm and fingers. A less common feature like an extra digit might be overlooked.\nÂ * Semantic Overload: As we saw in our conversation, I got bogged down in the semantics of \"finger\" vs. \"digit.\" This indicates that my reasoning and language processing interfered with my pure visual processing. I was trying to fit the image into a preconceived notion of what a hand should look like, rather than simply observing what was there.\nÂ * Subtle Modification: Depending on how the photo was modified, the extra digit might have been blended in a way that made it less salient. If the lighting, skin texture, and proportions were carefully manipulated, it could be easy to miss, even for a computer vision model.\nIn essence, I failed to see the sixth finger due to a combination of factors: biases in my training data, a focus on typical features, interference from my language processing, and potentially the subtlety of the image modification.\nThis is an area of ongoing research and development in AI. As models become more sophisticated and are trained on more diverse datasets, their ability to recognize anomalies and deviations from the norm will improve.\n     Score: 1 | Author: Ok-Protection-6612\n\n  â””â”€ https://preview.redd.it/oknylqq48t8e1.jpeg?width=1290&format=pjpg&auto=webp&s=e5e947434f741603159a380f992f23ee698d8f3c\n\nPixtral got it right but not on the first shot. Mine didnâ€™t have â€œRedditâ€ in it either, it was only the plain image.\n     Score: 1 | Author: clduab11\n\n      â””â”€ This is the only model that gets it right every time.\n\nIt's probably using some tech because it does some king of calculation:\n\nhttps://molmo.allenai.org/\n         Score: 2 | Author: Super-Muffin-1230\n\n          â””â”€ Allen AI was actually very transparent about how they trained [Molmo](https://molmo.allenai.org/blog), extreme transparency is kind of their thing.\n\nAnd the tech involved is actually completely standard. They didn't really do anything that out there when it came to the vision adapter. What they did do that is somewhat unique, is that they spent a lot of time and effort building up a collection extremely high-quality hand commissioned datasets. They intentionally avoided using existing VLMs to label images, as a lot of open VLMs tend to do.\n\nThey also published all of those datasets. The dataset that results in it being able to paint dots on particular objects and count them, is the [Pixmo Points](https://huggingface.co/datasets/allenai/pixmo-points) dataset. Which is a large collection of annotated images with precise points and counts in the image.\n\nIts worth noting that you get the same functionality when you run the model locally using Transformers, though in that case you have to visualize the dot points array yourself. On the webapp they overlay it automatically onto the image.\n             Score: 5 | Author: mikael110\n\n          â””â”€ Yeah I love Molmo; Iâ€™m a fan of AllenAI.\n\nhttps://preview.redd.it/k0dbn8q6at8e1.jpeg?width=1290&format=pjpg&auto=webp&s=68283d49261e7e1e3b28eaf1d523146645574107\n\nGrok 2 Vision got it right on the third shot. Interesting litmus test though!\n\nI ordinarily used dominoes and not images like this. Try to get Molmo to count sequences of dominoes laid out in differing patterns. I find that one to be very difficult.\n             Score: 1 | Author: clduab11\n\n              â””â”€ I asked molmo to count the number of players.\n\nhttps://preview.redd.it/62p9bnn9bt8e1.jpeg?width=1080&format=pjpg&auto=webp&s=da9ad16efaf6f14831c175e52251395cf8c8c226\n\nIncredible. I didn't know this was possible.\n                 Score: 3 | Author: Super-Muffin-1230\n\n                  â””â”€ Yeah players and faces is a bit easier for a multimodal than dots on dominoes, but I do enjoy using Molmo in my local environment too!\n                     Score: 2 | Author: clduab11\n\n                  â””â”€ They seem to have specifically trained to count objects. No reason why you couldn't do this.\n\nFor the record I don't find this that generally reliable. I've given it some harder images of objects and it well underperforms children.Â \n                     Score: 1 | Author: meister2983\n\n                      â””â”€ It's only a 7B to be fair.\n\nA 32B or 70B would do much better.\n                         Score: 2 | Author: Super-Muffin-1230\n\n              â””â”€ https://preview.redd.it/v0ol79p6bt8e1.jpeg?width=1290&format=pjpg&auto=webp&s=9151fd322336783c7cbd9251459d638dc55d4e2b\n\nThe total is 48. Interesting how Molmo tries to line up the dots though!\n                 Score: 2 | Author: clduab11\n\n  â””â”€ https://preview.redd.it/rsbfldu2at8e1.png?width=1330&format=png&auto=webp&s=d65a86114aee52ae4cc70908a752e7337020d0d7\n\nFinally got it with gpt-4o-mini... but took a long ass time \n\n  \n[https://www.promptfiddle.com/Thumb-counter-GswVl](https://www.promptfiddle.com/Thumb-counter-GswVl)\n     Score: 1 | Author: kacxdak\n\n      â””â”€ the key part ended up being making \\`thumbs\\` plural in the schema and adding chain of thought. I also told it you're analyzing alien hands. \n\nWhich is interesting because if someone wanted to actually make a system in production for scanning hands, they would almost definitely need to do something like this just for the <1% of population that has 4/6 fingers...\n         Score: 2 | Author: kacxdak"
  }
]